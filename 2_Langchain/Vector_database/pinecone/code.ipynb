{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5173c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbd3dd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['HF_TOKEN']=os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings=HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.004072181880474091,\n",
       " 0.03218543156981468,\n",
       " -0.031980570405721664,\n",
       " -0.0039020308759063482,\n",
       " -0.032634373754262924,\n",
       " -0.10823628306388855,\n",
       " 0.020767612382769585,\n",
       " 0.006769743748009205,\n",
       " -0.03243338689208031,\n",
       " 0.041988443583250046,\n",
       " -0.042269278317689896,\n",
       " 0.021122528240084648,\n",
       " 0.08300084620714188,\n",
       " -0.010581500828266144,\n",
       " -0.009820735082030296,\n",
       " -0.07071002572774887,\n",
       " -0.0810021311044693,\n",
       " -0.06620079278945923,\n",
       " -0.038167618215084076,\n",
       " -0.0009679549257270992,\n",
       " -0.005489090457558632,\n",
       " -0.0391065739095211,\n",
       " -0.04533586651086807,\n",
       " -0.0026936891954392195,\n",
       " 0.01686101220548153,\n",
       " 0.07699701189994812,\n",
       " -0.015226428396999836,\n",
       " -0.026579372584819794,\n",
       " 0.012856611050665379,\n",
       " -0.05546896159648895,\n",
       " -0.045117106288671494,\n",
       " 0.10099875926971436,\n",
       " 0.10067621618509293,\n",
       " 0.08444570749998093,\n",
       " 0.03245962783694267,\n",
       " 0.04033583775162697,\n",
       " 0.058801937848329544,\n",
       " -0.07994294166564941,\n",
       " -0.022445879876613617,\n",
       " 0.023812495172023773,\n",
       " -0.07433754205703735,\n",
       " 0.008814584463834763,\n",
       " 0.023365963250398636,\n",
       " -0.0016833090921863914,\n",
       " -0.008884061127901077,\n",
       " 0.01777406595647335,\n",
       " -0.044746506959199905,\n",
       " -0.028835056349635124,\n",
       " -0.0027748786378651857,\n",
       " 0.003933309577405453,\n",
       " -0.0878390371799469,\n",
       " -0.024033518508076668,\n",
       " -0.007063040044158697,\n",
       " -0.05027398839592934,\n",
       " -0.013085152953863144,\n",
       " 0.015319877304136753,\n",
       " 0.06948569416999817,\n",
       " -0.01534497831016779,\n",
       " -0.021631650626659393,\n",
       " -0.0004840951878577471,\n",
       " -0.10392758250236511,\n",
       " 0.021387731656432152,\n",
       " -0.036391448229551315,\n",
       " 0.09693155437707901,\n",
       " 0.06566502898931503,\n",
       " -0.01985928788781166,\n",
       " -0.01906430535018444,\n",
       " -0.011566735804080963,\n",
       " -0.017255421727895737,\n",
       " -0.08904654532670975,\n",
       " -0.12669454514980316,\n",
       " 0.03432441130280495,\n",
       " -0.008665005676448345,\n",
       " 0.09617514908313751,\n",
       " 0.04862494766712189,\n",
       " -0.05314713716506958,\n",
       " 0.0022395027335733175,\n",
       " -0.05636952444911003,\n",
       " 0.06289893388748169,\n",
       " -0.0016420261235907674,\n",
       " 0.02040010504424572,\n",
       " -0.057477157562971115,\n",
       " -0.051404982805252075,\n",
       " 0.056938353925943375,\n",
       " 0.025000661611557007,\n",
       " 0.003583995159715414,\n",
       " 0.04806561395525932,\n",
       " 0.0796859860420227,\n",
       " 0.005029043648391962,\n",
       " 0.0002372785093029961,\n",
       " -0.04624836519360542,\n",
       " -0.0014786138199269772,\n",
       " 0.009929603897035122,\n",
       " 0.047758013010025024,\n",
       " -0.07861406356096268,\n",
       " 0.010943264700472355,\n",
       " 0.051008760929107666,\n",
       " -0.05651641637086868,\n",
       " -0.09135468304157257,\n",
       " 0.017200827598571777,\n",
       " -0.012166129425168037,\n",
       " -0.010383621789515018,\n",
       " 0.03480930253863335,\n",
       " 0.03053997829556465,\n",
       " -0.029510395601391792,\n",
       " -0.00788146909326315,\n",
       " 0.047727856785058975,\n",
       " 0.004862973932176828,\n",
       " 0.04667652025818825,\n",
       " -0.058572474867105484,\n",
       " -0.03506269305944443,\n",
       " -0.041173867881298065,\n",
       " 0.04443400725722313,\n",
       " -0.04758881404995918,\n",
       " 0.04151102900505066,\n",
       " -0.005870653782039881,\n",
       " -0.05210496485233307,\n",
       " 0.06591371446847916,\n",
       " 0.018737463280558586,\n",
       " 0.06056929752230644,\n",
       " 0.04267429560422897,\n",
       " 0.022192347794771194,\n",
       " -0.008766385726630688,\n",
       " -0.008045143447816372,\n",
       " -0.011228564195334911,\n",
       " -0.007917366921901703,\n",
       " 0.016591902822256088,\n",
       " -9.452597497499296e-33,\n",
       " -0.04720745608210564,\n",
       " -0.032576996833086014,\n",
       " 0.01538185402750969,\n",
       " 0.14393305778503418,\n",
       " 0.010588932782411575,\n",
       " -0.006153905298560858,\n",
       " 0.0027705077081918716,\n",
       " 0.1268681138753891,\n",
       " -0.07303579151630402,\n",
       " 0.03876885771751404,\n",
       " 0.03543192520737648,\n",
       " 0.0003430744691286236,\n",
       " 0.01601000688970089,\n",
       " 0.14485621452331543,\n",
       " 0.028156226500868797,\n",
       " 0.00026943793636746705,\n",
       " -0.03888746723532677,\n",
       " 0.027946194633841515,\n",
       " -0.06491335481405258,\n",
       " 0.03313785046339035,\n",
       " 0.019687658175826073,\n",
       " -0.01024531852453947,\n",
       " 0.04043998569250107,\n",
       " -0.0017788520781323314,\n",
       " 0.031234150752425194,\n",
       " -0.012334217317402363,\n",
       " 0.012854219414293766,\n",
       " -0.05517648532986641,\n",
       " 0.12479997426271439,\n",
       " 0.0023430674336850643,\n",
       " -0.04097621515393257,\n",
       " -0.029240012168884277,\n",
       " -0.05517449229955673,\n",
       " 0.05004953593015671,\n",
       " 0.012358426116406918,\n",
       " 0.001094023697078228,\n",
       " -0.02416415326297283,\n",
       " -0.043807633221149445,\n",
       " 0.013590918853878975,\n",
       " 0.01577834226191044,\n",
       " -0.04923662170767784,\n",
       " -0.0029530925676226616,\n",
       " 0.0654698982834816,\n",
       " -0.009944030083715916,\n",
       " 0.050257422029972076,\n",
       " -0.02173791266977787,\n",
       " -0.010257041081786156,\n",
       " 0.003458845429122448,\n",
       " 0.04902705177664757,\n",
       " 0.030019212514162064,\n",
       " -0.09050096571445465,\n",
       " 0.08579543977975845,\n",
       " 0.061540864408016205,\n",
       " 0.05324584245681763,\n",
       " 0.020323630422353745,\n",
       " 0.006733651272952557,\n",
       " 0.029783593490719795,\n",
       " -0.04031578451395035,\n",
       " -0.04926414415240288,\n",
       " 0.1117352694272995,\n",
       " -0.017117418348789215,\n",
       " 0.12274681031703949,\n",
       " 0.02879882976412773,\n",
       " -0.03818530589342117,\n",
       " 0.010717197321355343,\n",
       " 0.02422875538468361,\n",
       " -0.02112656831741333,\n",
       " -0.011222478933632374,\n",
       " 0.0756467953324318,\n",
       " 0.08414493501186371,\n",
       " -0.023156430572271347,\n",
       " -0.004201651085168123,\n",
       " -0.02319398708641529,\n",
       " 0.03274576738476753,\n",
       " -0.05496801808476448,\n",
       " -0.011672290042042732,\n",
       " 0.007552825380116701,\n",
       " -0.018391743302345276,\n",
       " -0.02241773158311844,\n",
       " -0.05559612065553665,\n",
       " 0.06253340095281601,\n",
       " -0.029054734855890274,\n",
       " 0.0023001108784228563,\n",
       " -0.09006321430206299,\n",
       " 0.04038887470960617,\n",
       " -0.010360115207731724,\n",
       " 0.011834422126412392,\n",
       " -0.13705120980739594,\n",
       " 0.010581006295979023,\n",
       " -0.06657379865646362,\n",
       " 0.0036210392136126757,\n",
       " -0.027064628899097443,\n",
       " 0.038976915180683136,\n",
       " 0.011880672536790371,\n",
       " 0.032869238406419754,\n",
       " 5.428503809100358e-33,\n",
       " 0.047235384583473206,\n",
       " 0.06365317106246948,\n",
       " -0.059038542211055756,\n",
       " 0.031457554548978806,\n",
       " -0.05246739089488983,\n",
       " -0.03257877379655838,\n",
       " 0.034530069679021835,\n",
       " 0.004879134241491556,\n",
       " -0.06887844204902649,\n",
       " 0.12879151105880737,\n",
       " 0.003927715588361025,\n",
       " -0.02322251908481121,\n",
       " -0.053904466331005096,\n",
       " 0.020871490240097046,\n",
       " -0.03513796254992485,\n",
       " -0.02108362875878811,\n",
       " -0.03753162547945976,\n",
       " 0.007533281110227108,\n",
       " -0.06801486760377884,\n",
       " -0.037740111351013184,\n",
       " -0.04767356812953949,\n",
       " 0.07675250619649887,\n",
       " -0.08158858865499496,\n",
       " 0.02517920732498169,\n",
       " 0.033475685864686966,\n",
       " -0.030723275616765022,\n",
       " -0.009959655813872814,\n",
       " 0.009803279303014278,\n",
       " 0.024747971445322037,\n",
       " 0.05794459208846092,\n",
       " -0.034639623016119,\n",
       " 0.027176253497600555,\n",
       " -0.08341532945632935,\n",
       " -0.03607999533414841,\n",
       " 0.09692328423261642,\n",
       " -0.000811580684967339,\n",
       " 0.01489313319325447,\n",
       " -0.09709072858095169,\n",
       " -0.00934741273522377,\n",
       " 0.02113231271505356,\n",
       " 0.04533376544713974,\n",
       " 0.027245376259088516,\n",
       " 0.07595750689506531,\n",
       " 0.09991319477558136,\n",
       " -0.02716229297220707,\n",
       " 0.05144757032394409,\n",
       " -0.028530128300189972,\n",
       " -0.020577246323227882,\n",
       " -0.05437798425555229,\n",
       " -0.03326234593987465,\n",
       " -0.06360477209091187,\n",
       " -0.06592202186584473,\n",
       " 0.07525473833084106,\n",
       " -0.10057247430086136,\n",
       " -0.007863915525376797,\n",
       " -0.00128694879822433,\n",
       " 0.016397802159190178,\n",
       " 0.0157108586281538,\n",
       " 0.017771312966942787,\n",
       " -0.02074703760445118,\n",
       " -0.08032863587141037,\n",
       " -0.011240885592997074,\n",
       " 0.0878392681479454,\n",
       " 0.07878806442022324,\n",
       " -0.005321551579982042,\n",
       " -0.07427624613046646,\n",
       " 0.0035853784065693617,\n",
       " 0.004091187845915556,\n",
       " -0.05003263056278229,\n",
       " -0.07183787226676941,\n",
       " 0.04990842938423157,\n",
       " 0.07285340130329132,\n",
       " -0.042065393179655075,\n",
       " -0.007615971378982067,\n",
       " -0.07280518114566803,\n",
       " 0.00543793011456728,\n",
       " 0.015672815963625908,\n",
       " -0.01574842445552349,\n",
       " -0.0563792884349823,\n",
       " 0.047422196716070175,\n",
       " 0.019806301221251488,\n",
       " 0.0037792304065078497,\n",
       " 0.030593156814575195,\n",
       " 0.062244661152362823,\n",
       " -0.08450644463300705,\n",
       " 0.13712434470653534,\n",
       " 0.011791927739977837,\n",
       " 0.04683039337396622,\n",
       " -0.08275370299816132,\n",
       " -0.0021490466315299273,\n",
       " -0.019366774708032608,\n",
       " 0.11344533413648605,\n",
       " 0.031320925801992416,\n",
       " 0.006455740891396999,\n",
       " -0.0424053855240345,\n",
       " -2.261683995641306e-08,\n",
       " -0.046677861362695694,\n",
       " -0.07513795793056488,\n",
       " -0.0039697447791695595,\n",
       " -0.017440011724829674,\n",
       " 0.016396738588809967,\n",
       " 0.05985948443412781,\n",
       " -0.009956439025700092,\n",
       " -0.08299218118190765,\n",
       " -0.09457623958587646,\n",
       " -0.008353560231626034,\n",
       " 0.07949342578649521,\n",
       " 0.056974247097969055,\n",
       " -0.11385704576969147,\n",
       " 0.056116439402103424,\n",
       " 0.10017841309309006,\n",
       " 0.0013587482972070575,\n",
       " 0.05472739040851593,\n",
       " 4.922054813505383e-06,\n",
       " 0.004206600598990917,\n",
       " -0.018844764679670334,\n",
       " -0.007318644784390926,\n",
       " 0.044748421758413315,\n",
       " -0.011225166730582714,\n",
       " 0.1002630963921547,\n",
       " -0.07987447828054428,\n",
       " -0.036303725093603134,\n",
       " 0.058600444346666336,\n",
       " 0.11014282703399658,\n",
       " 0.02493591234087944,\n",
       " -0.06847396492958069,\n",
       " 0.07066351175308228,\n",
       " 0.0269103292375803,\n",
       " -0.04128281772136688,\n",
       " 0.006309858988970518,\n",
       " -0.034036826342344284,\n",
       " 0.0067808073945343494,\n",
       " 0.013966395519673824,\n",
       " 0.014066857285797596,\n",
       " 0.008482728153467178,\n",
       " -0.016530631110072136,\n",
       " -0.07705710083246231,\n",
       " 0.02336038276553154,\n",
       " -0.013042747974395752,\n",
       " -0.0547163300216198,\n",
       " -0.05204758048057556,\n",
       " -0.03603583201766014,\n",
       " -0.0100774010643363,\n",
       " -0.08759937435388565,\n",
       " -0.02642577514052391,\n",
       " -0.11277303844690323,\n",
       " -0.03399019315838814,\n",
       " 0.004255054052919149,\n",
       " 0.01954019069671631,\n",
       " 0.004693187307566404,\n",
       " 0.0969458818435669,\n",
       " 0.036619916558265686,\n",
       " -0.08819572627544403,\n",
       " -0.007264246232807636,\n",
       " -0.02046760357916355,\n",
       " 0.1310431808233261,\n",
       " 0.06693849712610245,\n",
       " 0.10607634484767914,\n",
       " -0.0011710883118212223,\n",
       " 0.027272701263427734]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.embed_query(\"Hello world, I love programming! . This is a test.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings.embed_query(\"Hello world, I love programming! . This is a test.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6015960f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv(\"GOOGLE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a606d69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.033388201147317886,\n",
       " 0.034539803862571716,\n",
       " 0.059474579989910126,\n",
       " 0.05928615480661392,\n",
       " -0.06353538483381271,\n",
       " -0.06819586455821991,\n",
       " 0.08823323249816895,\n",
       " 0.0344407856464386,\n",
       " -0.03278515860438347,\n",
       " -0.015814995393157005,\n",
       " 0.020981667563319206,\n",
       " -0.018340280279517174,\n",
       " -0.03983214125037193,\n",
       " -0.08047076314687729,\n",
       " -0.014469259418547153,\n",
       " 0.03326486423611641,\n",
       " 0.01425926387310028,\n",
       " -0.03404999524354935,\n",
       " -0.142915740609169,\n",
       " -0.023083265870809555,\n",
       " -0.02138010412454605,\n",
       " 0.0026335634756833315,\n",
       " -0.04729275032877922,\n",
       " -0.010752726346254349,\n",
       " -0.06866799294948578,\n",
       " 0.03112499974668026,\n",
       " 0.07594592869281769,\n",
       " 0.0011283049825578928,\n",
       " 0.011631982401013374,\n",
       " -0.036039214581251144,\n",
       " 0.04483765363693237,\n",
       " 0.01839079149067402,\n",
       " 0.12672799825668335,\n",
       " -0.001359735382720828,\n",
       " 0.008206715807318687,\n",
       " 0.06909963488578796,\n",
       " -0.0807635709643364,\n",
       " -0.05841311439871788,\n",
       " 0.05375451594591141,\n",
       " 0.026227623224258423,\n",
       " -0.00682859867811203,\n",
       " -0.05635840445756912,\n",
       " 0.0032929950393736362,\n",
       " -0.07250180840492249,\n",
       " 0.06960921734571457,\n",
       " 0.031674399971961975,\n",
       " -0.012384780682623386,\n",
       " 0.023199237883090973,\n",
       " 0.08131053298711777,\n",
       " 0.00027830112958326936,\n",
       " -0.12659239768981934,\n",
       " -0.04998629540205002,\n",
       " -0.03565254062414169,\n",
       " 0.04856065660715103,\n",
       " 0.09733067452907562,\n",
       " 0.06224418804049492,\n",
       " -0.037504829466342926,\n",
       " 0.008118381723761559,\n",
       " 0.027651414275169373,\n",
       " -0.043216656893491745,\n",
       " 0.01624850183725357,\n",
       " 0.0022868122905492783,\n",
       " 0.003097043139860034,\n",
       " -0.015322081744670868,\n",
       " 0.03742990642786026,\n",
       " -0.010506647638976574,\n",
       " -0.05321492254734039,\n",
       " -0.039694707840681076,\n",
       " -0.052877578884363174,\n",
       " -0.030448229983448982,\n",
       " -0.011697022244334221,\n",
       " 0.07245180755853653,\n",
       " -0.07213432341814041,\n",
       " 0.039102256298065186,\n",
       " -0.03716370463371277,\n",
       " 0.026422275230288506,\n",
       " 0.026734258979558945,\n",
       " -0.031146880239248276,\n",
       " 0.06340930610895157,\n",
       " -0.01694674789905548,\n",
       " 0.0063436501659452915,\n",
       " -0.02548304758965969,\n",
       " -0.015998929738998413,\n",
       " 0.01468464732170105,\n",
       " -0.04103194549679756,\n",
       " 0.056689441204071045,\n",
       " 0.051890779286623,\n",
       " 0.012766428291797638,\n",
       " 0.010396684519946575,\n",
       " 0.036034632474184036,\n",
       " -0.07487251609563828,\n",
       " 0.022285528481006622,\n",
       " 0.05366942659020424,\n",
       " 0.021017184481024742,\n",
       " 0.01070323120802641,\n",
       " 0.011209463700652122,\n",
       " 0.022165242582559586,\n",
       " -0.03350186347961426,\n",
       " -0.13790257275104523,\n",
       " 0.17661654949188232,\n",
       " 0.03291358798742294,\n",
       " 0.07648545503616333,\n",
       " -0.056457702070474625,\n",
       " 0.03820186108350754,\n",
       " -0.05886796861886978,\n",
       " 0.016183679923415184,\n",
       " -0.0029855016618967056,\n",
       " 0.008209964260458946,\n",
       " 0.026603659614920616,\n",
       " 0.034101277589797974,\n",
       " -0.003371298545971513,\n",
       " -0.04683653265237808,\n",
       " 0.029342366382479668,\n",
       " -0.018165402114391327,\n",
       " 0.09393948316574097,\n",
       " 0.0166737362742424,\n",
       " -0.016232209280133247,\n",
       " 0.07100321352481842,\n",
       " 0.04189832881093025,\n",
       " -0.012874997220933437,\n",
       " 0.02733328379690647,\n",
       " -0.037691812962293625,\n",
       " -0.010565720498561859,\n",
       " 0.08810009807348251,\n",
       " 0.03338446468114853,\n",
       " -0.0023000610526651144,\n",
       " -0.020081721246242523,\n",
       " -3.438964926654251e-33,\n",
       " 0.003885385813191533,\n",
       " -0.045698028057813644,\n",
       " 0.03672376647591591,\n",
       " 0.10973254591226578,\n",
       " 0.005294251721352339,\n",
       " -0.03384030610322952,\n",
       " -0.057188041508197784,\n",
       " -0.03098653070628643,\n",
       " 0.0282085370272398,\n",
       " 0.014682859182357788,\n",
       " -0.0056138248182833195,\n",
       " 0.02814444899559021,\n",
       " -0.06591308861970901,\n",
       " 0.01608217880129814,\n",
       " 0.04844910651445389,\n",
       " 0.07509640604257584,\n",
       " -0.004293231759220362,\n",
       " 0.0263045746833086,\n",
       " -0.02851446531713009,\n",
       " 0.022873952984809875,\n",
       " -0.05280346795916557,\n",
       " -0.060665033757686615,\n",
       " 0.019528521224856377,\n",
       " 0.054101862013339996,\n",
       " 0.02175346203148365,\n",
       " -0.025309914723038673,\n",
       " 0.03161471337080002,\n",
       " -0.12111620604991913,\n",
       " 0.04928331449627876,\n",
       " 0.0027341076638549566,\n",
       " -0.038959283381700516,\n",
       " -0.02350742183625698,\n",
       " 0.010390612296760082,\n",
       " 0.02667587250471115,\n",
       " -0.02038608305156231,\n",
       " 0.013104474171996117,\n",
       " 0.012831296771764755,\n",
       " -0.027721179649233818,\n",
       " -0.07600441575050354,\n",
       " 0.03969912976026535,\n",
       " -0.06335607916116714,\n",
       " 0.06014363095164299,\n",
       " 0.05248519778251648,\n",
       " 0.008374607190489769,\n",
       " 0.015201497822999954,\n",
       " -0.01872258633375168,\n",
       " 0.01212179847061634,\n",
       " -0.014375110156834126,\n",
       " 0.033597685396671295,\n",
       " -0.01308043859899044,\n",
       " -0.06113573908805847,\n",
       " 0.029406405985355377,\n",
       " -0.09374042600393295,\n",
       " -0.002057623350992799,\n",
       " 0.024026259779930115,\n",
       " -0.04306028410792351,\n",
       " -0.03385312110185623,\n",
       " -0.0036304700188338757,\n",
       " 0.005760235246270895,\n",
       " 0.01923433318734169,\n",
       " 0.024349471554160118,\n",
       " 0.0710911750793457,\n",
       " -0.044834986329078674,\n",
       " 0.07316724956035614,\n",
       " -0.08264461904764175,\n",
       " 0.0054279230535030365,\n",
       " 0.023218734189867973,\n",
       " 0.060967519879341125,\n",
       " 0.09460730105638504,\n",
       " -0.014135172590613365,\n",
       " -0.041771095246076584,\n",
       " -0.027401898056268692,\n",
       " 0.03853408619761467,\n",
       " -0.007350042928010225,\n",
       " -0.007266181521117687,\n",
       " 0.048032596707344055,\n",
       " -0.011426649056375027,\n",
       " -0.06901123374700546,\n",
       " 0.037151314318180084,\n",
       " -0.06476700305938721,\n",
       " -0.06643083691596985,\n",
       " -0.001176641322672367,\n",
       " -0.02179589308798313,\n",
       " -0.007523735519498587,\n",
       " 0.06725426018238068,\n",
       " 0.008094736374914646,\n",
       " -0.038112886250019073,\n",
       " -0.08759458363056183,\n",
       " 0.03036235086619854,\n",
       " -0.042037904262542725,\n",
       " -0.06107688695192337,\n",
       " 0.012958253733813763,\n",
       " 0.005050809122622013,\n",
       " 0.018419791013002396,\n",
       " -0.12826380133628845,\n",
       " 2.62487429361136e-33,\n",
       " 0.0888892412185669,\n",
       " 0.03213626891374588,\n",
       " -0.10708096623420715,\n",
       " -0.016275160014629364,\n",
       " -0.0415031798183918,\n",
       " 0.0020868987776339054,\n",
       " -0.06067206710577011,\n",
       " 0.1204824447631836,\n",
       " -0.08354715257883072,\n",
       " 0.05011679232120514,\n",
       " 0.0011805907124653459,\n",
       " -0.05077018216252327,\n",
       " 0.059968817979097366,\n",
       " 0.054858896881341934,\n",
       " 0.06972207129001617,\n",
       " 0.004157168325036764,\n",
       " 0.12240331619977951,\n",
       " 0.03817792609333992,\n",
       " -0.01899203658103943,\n",
       " 0.012684145011007786,\n",
       " -0.03257124498486519,\n",
       " 0.02660112828016281,\n",
       " -0.059803131967782974,\n",
       " -0.024400964379310608,\n",
       " -0.016547169536352158,\n",
       " 0.02027438022196293,\n",
       " -0.023540074005723,\n",
       " 0.08794984966516495,\n",
       " -0.09462472051382065,\n",
       " -0.056649498641490936,\n",
       " 0.07793808728456497,\n",
       " -0.0145401731133461,\n",
       " -0.04598597437143326,\n",
       " 0.03597734868526459,\n",
       " 0.01722737029194832,\n",
       " 0.1085493341088295,\n",
       " 0.023995401337742805,\n",
       " -0.09443827718496323,\n",
       " 0.021734846755862236,\n",
       " -0.035141877830028534,\n",
       " -0.015563040971755981,\n",
       " -0.00905606523156166,\n",
       " -0.026420576497912407,\n",
       " 0.09819944202899933,\n",
       " -0.051732853055000305,\n",
       " -0.05118061974644661,\n",
       " -0.04413073882460594,\n",
       " 0.060778889805078506,\n",
       " -0.01092186663299799,\n",
       " -0.0016202396946027875,\n",
       " -0.12291138619184494,\n",
       " -0.08137030154466629,\n",
       " -0.023045791313052177,\n",
       " -0.050796691328287125,\n",
       " -0.1166769489645958,\n",
       " 0.025221604853868484,\n",
       " -0.019859882071614265,\n",
       " 0.04968450590968132,\n",
       " -0.013690246269106865,\n",
       " 0.004341193940490484,\n",
       " -0.014368368312716484,\n",
       " 0.04770711064338684,\n",
       " 0.03718505799770355,\n",
       " 0.02282983809709549,\n",
       " -0.04654855653643608,\n",
       " 0.06936842948198318,\n",
       " -0.02132510021328926,\n",
       " 0.02957007847726345,\n",
       " 0.0009862963343039155,\n",
       " -0.0332183837890625,\n",
       " 0.04180171340703964,\n",
       " -0.005182821769267321,\n",
       " -0.020640278235077858,\n",
       " 0.04860807582736015,\n",
       " -0.04133269563317299,\n",
       " -0.005364660173654556,\n",
       " -0.02189500257372856,\n",
       " 0.02127024158835411,\n",
       " 0.018460959196090698,\n",
       " -0.03659111261367798,\n",
       " -0.057284701615571976,\n",
       " -0.003445934969931841,\n",
       " -0.04625878483057022,\n",
       " 0.05134572461247444,\n",
       " 0.025934023782610893,\n",
       " 0.03859254717826843,\n",
       " 0.06607189774513245,\n",
       " -0.01730244792997837,\n",
       " -0.01059806253761053,\n",
       " 0.022652043029665947,\n",
       " 0.03672377020120621,\n",
       " 0.03584650531411171,\n",
       " 0.012036584317684174,\n",
       " 0.03178591653704643,\n",
       " -0.12105198204517365,\n",
       " -1.513083525139791e-08,\n",
       " 0.006866068113595247,\n",
       " -0.027710258960723877,\n",
       " 0.08934702724218369,\n",
       " 0.07790025323629379,\n",
       " 0.06404796987771988,\n",
       " 0.03166110813617706,\n",
       " -0.07114409655332565,\n",
       " -0.04326840490102768,\n",
       " -0.03240786865353584,\n",
       " -0.021455753594636917,\n",
       " -0.00830535963177681,\n",
       " 0.0380602590739727,\n",
       " -0.00011358146730344743,\n",
       " 0.012233693152666092,\n",
       " 0.12013918161392212,\n",
       " 0.03023669682443142,\n",
       " -0.05191420763731003,\n",
       " -0.011444023810327053,\n",
       " -0.04784311726689339,\n",
       " -0.07834547758102417,\n",
       " 0.032210297882556915,\n",
       " -0.02586168609559536,\n",
       " -0.0020645565818995237,\n",
       " -0.02923075295984745,\n",
       " -0.019974663853645325,\n",
       " -0.03496573120355606,\n",
       " -0.014112554490566254,\n",
       " 0.03993986174464226,\n",
       " -0.06896212697029114,\n",
       " 0.05589039996266365,\n",
       " -0.012570522725582123,\n",
       " 0.18196909129619598,\n",
       " -0.012776450254023075,\n",
       " -0.0011512666242197156,\n",
       " 0.028124788776040077,\n",
       " 0.011322940699756145,\n",
       " 0.04628046602010727,\n",
       " 0.016169795766472816,\n",
       " 0.026298951357603073,\n",
       " -0.054048750549554825,\n",
       " -0.026807144284248352,\n",
       " 0.06764830648899078,\n",
       " 0.010659350082278252,\n",
       " -0.1292617917060852,\n",
       " 0.06938320398330688,\n",
       " 0.030720476061105728,\n",
       " 0.03887750953435898,\n",
       " -0.14078205823898315,\n",
       " 0.051911916583776474,\n",
       " -0.0679067075252533,\n",
       " -0.02985662966966629,\n",
       " 0.01736200973391533,\n",
       " 0.08236216753721237,\n",
       " 0.11180814355611801,\n",
       " 0.09893389791250229,\n",
       " 0.057195425033569336,\n",
       " 0.0159031692892313,\n",
       " -0.04091336578130722,\n",
       " -0.012436417862772942,\n",
       " 0.020249152556061745,\n",
       " 0.06743750721216202,\n",
       " 0.03933357074856758,\n",
       " 0.052080992609262466,\n",
       " -0.019405055791139603]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Switch back to HuggingFace embeddings due to Google API quota limit\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "embeddings.embed_query(\"Hello AI\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eab178f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pinecone\n",
      "  Using cached pinecone-7.3.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from pinecone) (2025.7.14)\n",
      "Collecting pinecone-plugin-assistant<2.0.0,>=1.6.0 (from pinecone)\n",
      "  Using cached pinecone_plugin_assistant-1.8.0-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting pinecone-plugin-interface<0.0.8,>=0.0.7 (from pinecone)\n",
      "  Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from pinecone) (4.14.1)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from pinecone) (2.5.0)\n",
      "Collecting packaging<25.0,>=24.2 (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone)\n",
      "  Using cached packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (2.32.4)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone) (3.10)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone) (1.17.0)\n",
      "Using cached pinecone-7.3.0-py3-none-any.whl (587 kB)\n",
      "Using cached pinecone_plugin_assistant-1.8.0-py3-none-any.whl (259 kB)\n",
      "Using cached packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Using cached pinecone_plugin_interface-0.0.7-py3-none-any.whl (6.2 kB)\n",
      "Installing collected packages: pinecone-plugin-interface, packaging, pinecone-plugin-assistant, pinecone\n",
      "\n",
      "  Attempting uninstall: packaging\n",
      "\n",
      "    Found existing installation: packaging 25.0\n",
      "\n",
      "    Uninstalling packaging-25.0:\n",
      "\n",
      "      Successfully uninstalled packaging-25.0\n",
      "\n",
      "   ---------- ----------------------------- 1/4 [packaging]\n",
      "   -------------------- ------------------- 2/4 [pinecone-plugin-assistant]\n",
      "   -------------------- ------------------- 2/4 [pinecone-plugin-assistant]\n",
      "   -------------------- ------------------- 2/4 [pinecone-plugin-assistant]\n",
      "   -------------------- ------------------- 2/4 [pinecone-plugin-assistant]\n",
      "   ------------------------------ --------- 3/4 [pinecone]\n",
      "   ------------------------------ --------- 3/4 [pinecone]\n",
      "   ------------------------------ --------- 3/4 [pinecone]\n",
      "   ------------------------------ --------- 3/4 [pinecone]\n",
      "   ------------------------------ --------- 3/4 [pinecone]\n",
      "   ------------------------------ --------- 3/4 [pinecone]\n",
      "   ------------------------------ --------- 3/4 [pinecone]\n",
      "   ------------------------------ --------- 3/4 [pinecone]\n",
      "   ------------------------------ --------- 3/4 [pinecone]\n",
      "   ------------------------------ --------- 3/4 [pinecone]\n",
      "   ------------------------------ --------- 3/4 [pinecone]\n",
      "   ------------------------------ --------- 3/4 [pinecone]\n",
      "   ---------------------------------------- 4/4 [pinecone]\n",
      "\n",
      "Successfully installed packaging-24.2 pinecone-7.3.0 pinecone-plugin-assistant-1.8.0 pinecone-plugin-interface-0.0.7\n"
     ]
    }
   ],
   "source": [
    "!pip install pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaec1212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "pinecone_api_key=os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bbe9c52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY=\"pcsk_2pyp4A_Cvaq5LMJ3a3FTJGMsnWtJYSB2SCN3AewGBTP73HksEDHc9mSGhGzKJkAC7W3kGV\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "pc = Pinecone(api_key=\"pcsk_2pyp4A_Cvaq5LMJ3a3FTJGMsnWtJYSB2SCN3AewGBTP73HksEDHc9mSGhGzKJkAC7W3kGV\")\n",
    "index = pc.Index(\"mongo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "#Serverless: Server will be Managed by the cloud provider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_name=\"mongo\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "650458bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.has_index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.has_index(\"mongo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a index\n",
    "if not pc.has_index(index_name):\n",
    "    pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=1024,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(cloud=\"aws\",region=\"us-east-1\")    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c32dd10e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the index\n",
    "index=pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d81d7727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_pinecone\n",
      "  Downloading langchain_pinecone-0.2.12-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.34 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from langchain_pinecone) (0.3.76)\n",
      "Requirement already satisfied: pinecone<8.0.0,>=6.0.0 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (7.3.0)\n",
      "Requirement already satisfied: numpy>=1.26.4 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from langchain_pinecone) (1.26.4)\n",
      "Requirement already satisfied: langchain-openai>=0.3.11 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from langchain_pinecone) (0.3.28)\n",
      "Requirement already satisfied: httpx>=0.28.0 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from langchain_pinecone) (0.28.1)\n",
      "Collecting simsimd>=5.9.11 (from langchain_pinecone)\n",
      "  Downloading simsimd-6.5.3-cp312-cp312-win_amd64.whl.metadata (71 kB)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (0.4.10)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (6.0.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (24.2)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (2.11.7)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (3.0.0)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (2025.7.14)\n",
      "Requirement already satisfied: pinecone-plugin-assistant<2.0.0,>=1.6.0 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (1.8.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (0.0.7)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (2.9.0.post0)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (2.5.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.3 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (2.32.4)\n",
      "Requirement already satisfied: aiohttp>=3.9.0 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (3.12.15)\n",
      "Collecting aiohttp-retry<3.0.0,>=2.9.1 (from pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone)\n",
      "  Downloading aiohttp_retry-2.9.1-py3-none-any.whl.metadata (8.8 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from requests<3.0.0,>=2.32.3->pinecone-plugin-assistant<2.0.0,>=1.6.0->pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (3.10)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from aiohttp>=3.9.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (1.20.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from httpx>=0.28.0->langchain_pinecone) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from httpx>=0.28.0->langchain_pinecone) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from httpcore==1.*->httpx>=0.28.0->langchain_pinecone) (0.16.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.86.0 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from langchain-openai>=0.3.11->langchain_pinecone) (1.98.0)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from langchain-openai>=0.3.11->langchain_pinecone) (0.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai>=0.3.11->langchain_pinecone) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai>=0.3.11->langchain_pinecone) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai>=0.3.11->langchain_pinecone) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from openai<2.0.0,>=1.86.0->langchain-openai>=0.3.11->langchain_pinecone) (4.67.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (0.4.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai>=0.3.11->langchain_pinecone) (2025.7.34)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.34->langchain_pinecone) (0.23.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone<8.0.0,>=6.0.0->pinecone[asyncio]<8.0.0,>=6.0.0->langchain_pinecone) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dell\\miniconda3\\envs\\rag\\lib\\site-packages (from tqdm>4->openai<2.0.0,>=1.86.0->langchain-openai>=0.3.11->langchain_pinecone) (0.4.6)\n",
      "Downloading langchain_pinecone-0.2.12-py3-none-any.whl (25 kB)\n",
      "Downloading aiohttp_retry-2.9.1-py3-none-any.whl (10.0 kB)\n",
      "Downloading simsimd-6.5.3-cp312-cp312-win_amd64.whl (94 kB)\n",
      "Installing collected packages: simsimd, aiohttp-retry, langchain_pinecone\n",
      "\n",
      "   -------------------------- ------------- 2/3 [langchain_pinecone]\n",
      "   ---------------------------------------- 3/3 [langchain_pinecone]\n",
      "\n",
      "Successfully installed aiohttp-retry-2.9.1 langchain_pinecone-0.2.12 simsimd-6.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\langchain_pinecone\\__init__.py:3: LangChainDeprecationWarning: As of langchain-core 0.3.0, LangChain uses pydantic v2 internally. The langchain_core.pydantic_v1 module was a compatibility shim for pydantic v1, and should no longer be used. Please update the code to import from Pydantic directly.\n",
      "\n",
      "For example, replace imports like: `from langchain_core.pydantic_v1 import BaseModel`\n",
      "with: `from pydantic import BaseModel`\n",
      "or the v1 compatibility namespace if you are working in a code base that has not been fully upgraded to pydantic 2 yet. \tfrom pydantic.v1 import BaseModel\n",
      "\n",
      "  from langchain_pinecone.vectorstores import Pinecone, PineconeVectorStore\n"
     ]
    }
   ],
   "source": [
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54ca443e",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store=PineconeVectorStore(index=index,embedding=embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search(\"what is a langchain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4aa27bca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "document_1 = Document(\n",
    "    page_content=\"I had chocolate chip pancakes and scrambled eggs for breakfast this morning.\",\n",
    "    metadata={\"source\": \"tweet\"},#additional info\n",
    ")\n",
    "\n",
    "document_2 = Document(\n",
    "    page_content=\"The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_3 = Document(\n",
    "    page_content=\"Building an exciting new project with LangChain - come check it out!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_4 = Document(\n",
    "    page_content=\"Robbers broke into the city bank and stole $1 million in cash.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_5 = Document(\n",
    "    page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_6 = Document(\n",
    "    page_content=\"Is the new iPhone worth the price? Read this review to find out.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_7 = Document(\n",
    "    page_content=\"The top 10 soccer players in the world right now.\",\n",
    "    metadata={\"source\": \"website\"},\n",
    ")\n",
    "\n",
    "document_8 = Document(\n",
    "    page_content=\"LangGraph is the best framework for building stateful, agentic applications!\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n",
    "\n",
    "document_9 = Document(\n",
    "    page_content=\"The stock market is down 500 points today due to fears of a recession.\",\n",
    "    metadata={\"source\": \"news\"},\n",
    ")\n",
    "\n",
    "document_10 = Document(\n",
    "    page_content=\"I have a bad feeling I am going to get deleted :(\",\n",
    "    metadata={\"source\": \"tweet\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28a15eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    document_1,\n",
    "    document_2,\n",
    "    document_3,\n",
    "    document_4,\n",
    "    document_5,\n",
    "    document_6,\n",
    "    document_7,\n",
    "    document_8,\n",
    "    document_9,\n",
    "    document_10,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1285ff9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'tweet'}, page_content='I had chocolate chip pancakes and scrambled eggs for breakfast this morning.'),\n",
       " Document(metadata={'source': 'news'}, page_content='The weather forecast for tomorrow is cloudy and overcast, with a high of 62 degrees.'),\n",
       " Document(metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!'),\n",
       " Document(metadata={'source': 'news'}, page_content='Robbers broke into the city bank and stole $1 million in cash.'),\n",
       " Document(metadata={'source': 'tweet'}, page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\"),\n",
       " Document(metadata={'source': 'website'}, page_content='Is the new iPhone worth the price? Read this review to find out.'),\n",
       " Document(metadata={'source': 'website'}, page_content='The top 10 soccer players in the world right now.'),\n",
       " Document(metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!'),\n",
       " Document(metadata={'source': 'news'}, page_content='The stock market is down 500 points today due to fears of a recession.'),\n",
       " Document(metadata={'source': 'tweet'}, page_content='I have a bad feeling I am going to get deleted :(')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9cad8c18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "range(0, 10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "range(len(documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7492f789",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "aff3ab19-73a4-44d3-9202-ad966d129da2\n",
      "1\n",
      "74020abd-66ae-480f-b262-c2c459fb9272\n",
      "2\n",
      "76856715-014f-4c3e-857a-54e39dfbac80\n",
      "3\n",
      "6d50ca2d-0372-465a-a952-b9293ea8fcc2\n",
      "4\n",
      "a525dce7-6fa8-48ff-ae1b-948bc38997c0\n",
      "5\n",
      "d061bd1c-b46c-4c33-be0c-25c1ee7db4b8\n",
      "6\n",
      "fcb73f3a-affd-4e17-bbca-8430631a6c43\n",
      "7\n",
      "49b15c4d-53e1-469f-883a-a5d66fbfed68\n",
      "8\n",
      "32aa1490-a90f-4754-a274-fcf5a1db64f2\n",
      "9\n",
      "5a42396c-3811-443c-83db-da0c8ff4cc68\n"
     ]
    }
   ],
   "source": [
    "for _ in range(len(documents)):\n",
    "    print(_)\n",
    "    print(str(uuid4()))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "055d6bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#universal indentification number\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d28ea3c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['678661d5-84e9-4828-87ab-831244633251',\n",
       " '4c93a95c-b024-4b01-9b3a-cfb543cda8d7',\n",
       " '825874be-7aef-43f3-a270-7a8259c486ca',\n",
       " 'a5e95bc3-3566-4f66-828c-3559259ed9ad',\n",
       " '3ecabad0-a15c-42fe-b4f6-42634321adb3',\n",
       " '5464427e-2803-41a5-8baa-4da637172687',\n",
       " '1d6cd50a-fca2-4ebb-a9fb-103a616e7570',\n",
       " 'b732de01-8f1a-4f44-b3b9-603e7fe44025',\n",
       " '168b7669-66d4-412e-9028-1237fde83c81',\n",
       " 'e35b7907-d939-4c06-a1f4-a0fb550160c2']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uuids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bef61c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['678661d5-84e9-4828-87ab-831244633251',\n",
       " '4c93a95c-b024-4b01-9b3a-cfb543cda8d7',\n",
       " '825874be-7aef-43f3-a270-7a8259c486ca',\n",
       " 'a5e95bc3-3566-4f66-828c-3559259ed9ad',\n",
       " '3ecabad0-a15c-42fe-b4f6-42634321adb3',\n",
       " '5464427e-2803-41a5-8baa-4da637172687',\n",
       " '1d6cd50a-fca2-4ebb-a9fb-103a616e7570',\n",
       " 'b732de01-8f1a-4f44-b3b9-603e7fe44025',\n",
       " '168b7669-66d4-412e-9028-1237fde83c81',\n",
       " 'e35b7907-d939-4c06-a1f4-a0fb550160c2']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete the existing index and recreate it with correct dimension\n",
    "if pc.has_index(index_name):\n",
    "\tpc.delete_index(index_name)\n",
    "\n",
    "# Create index with correct dimension for all-MiniLM-L6-v2 (384 dimensions)\n",
    "pc.create_index(\n",
    "\tname=index_name,\n",
    "\tdimension=384,  # Changed from 1024 to 384\n",
    "\tmetric=\"cosine\",\n",
    "\tspec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    ")\n",
    "\n",
    "# Reload the index\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# Recreate vector store with new index\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)\n",
    "\n",
    "# Now add the documents\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "44d2719e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search(\"what langchain provides to us?\",k=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2932c4c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='825874be-7aef-43f3-a270-7a8259c486ca', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!')]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c0c70e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search(\"what langchain provides to us?\",filter={\"source\": \"tweet\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "927965d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='e35b7907-d939-4c06-a1f4-a0fb550160c2', metadata={'source': 'tweet'}, page_content='I have a bad feeling I am going to get deleted :('),\n",
       " Document(id='b732de01-8f1a-4f44-b3b9-603e7fe44025', metadata={'source': 'tweet'}, page_content='LangGraph is the best framework for building stateful, agentic applications!'),\n",
       " Document(id='3ecabad0-a15c-42fe-b4f6-42634321adb3', metadata={'source': 'tweet'}, page_content=\"Wow! That was an amazing movie. I can't wait to see it again.\"),\n",
       " Document(id='825874be-7aef-43f3-a270-7a8259c486ca', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!')]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d4271049",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever=vector_store.as_retriever(\n",
    "    search_type=\"similarity_score_threshold\",\n",
    "    search_kwargs={\"score_threshold\": 0.7} #hyperparameter\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "17cef1db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='825874be-7aef-43f3-a270-7a8259c486ca', metadata={'source': 'tweet'}, page_content='Building an exciting new project with LangChain - come check it out!')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"langchain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da25cd41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"google\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5e26f314",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "model=ChatGoogleGenerativeAI(model='gemini-1.5-flash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "00506022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "e4bd7dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "pprint.pprint(prompt.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0975af4e",
   "metadata": {},
   "source": [
    "[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "325e8ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b11e1512",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt=PromptTemplate(\n",
    "    template=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\"\",\n",
    "    input_variables=['context', 'question']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cb94804e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "af0e035b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: what is a langchain? \\nContext: langchain is very super framework for LLM. \\nAnswer:\")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({\"question\":\"what is a langchain?\",\"context\":\"langchain is very super framework for LLM.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146f963f",
   "metadata": {},
   "source": [
    "StringPromptValue(text=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: what is a langchain? \\nContext: langchain is very super framework for LLM. \\nAnswer:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "80e9b613",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eab97bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7d8b1d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "83b12f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No relevant docs were retrieved using the relevance score threshold 0.7\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised NotFound: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 4.0 seconds as it raised NotFound: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 8.0 seconds as it raised NotFound: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 16.0 seconds as it raised NotFound: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n",
      "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 32.0 seconds as it raised NotFound: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods..\n"
     ]
    },
    {
     "ename": "NotFound",
     "evalue": "404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotFound\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrag_chain\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwhat is llama model?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\langchain_core\\runnables\\base.py:3245\u001b[39m, in \u001b[36mRunnableSequence.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m   3243\u001b[39m                 input_ = context.run(step.invoke, input_, config, **kwargs)\n\u001b[32m   3244\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3245\u001b[39m                 input_ = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3246\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m   3247\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1676\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   1673\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1674\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m1676\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:395\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    383\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    385\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    390\u001b[39m     **kwargs: Any,\n\u001b[32m    391\u001b[39m ) -> BaseMessage:\n\u001b[32m    392\u001b[39m     config = ensure_config(config)\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    394\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m395\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    396\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    397\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    398\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    399\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    400\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    402\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    405\u001b[39m     ).message\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1023\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1014\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1015\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1016\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1020\u001b[39m     **kwargs: Any,\n\u001b[32m   1021\u001b[39m ) -> LLMResult:\n\u001b[32m   1022\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1023\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:840\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    837\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    838\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    839\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m840\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    846\u001b[39m         )\n\u001b[32m    847\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    848\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1089\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1087\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1088\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1089\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1090\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1091\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1093\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1790\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmax_retries\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[32m   1789\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mmax_retries\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mself\u001b[39m.max_retries\n\u001b[32m-> \u001b[39m\u001b[32m1790\u001b[39m response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1792\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1795\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1796\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:238\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    229\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    231\u001b[39m params = (\n\u001b[32m    232\u001b[39m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs.items() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m _allowed_params_prediction_service}\n\u001b[32m    233\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (request := kwargs.get(\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m   (...)\u001b[39m\u001b[32m    236\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m kwargs\n\u001b[32m    237\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\tenacity\\__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\tenacity\\__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\tenacity\\__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:208\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_with_retry\u001b[39m(**kwargs: Any) -> Any:\n\u001b[32m    207\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m FailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    210\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mlocation is not supported\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m exc.message:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:869\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    866\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    868\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m869\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    873\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    877\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:294\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    290\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    291\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    292\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    293\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m294\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:156\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    153\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    155\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     next_sleep = \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    167\u001b[39m     time.sleep(next_sleep)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:214\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, sleep_iterator, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    209\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    210\u001b[39m         error_list,\n\u001b[32m    211\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    212\u001b[39m         original_timeout,\n\u001b[32m    213\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m214\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    216\u001b[39m     on_error_fn(exc)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:147\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    146\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m147\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    148\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    149\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\dell\\miniconda3\\envs\\RAG\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:77\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mNotFound\u001b[39m: 404 models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods."
     ]
    }
   ],
   "source": [
    "rag_chain.invoke(\"what is llama model?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433f18c3",
   "metadata": {},
   "source": [
    "# first complete the remaining part of this notebook(create a proper rag)\n",
    "\n",
    "\n",
    "\n",
    "# second assisgnment is: take a multiple pdf with text,image,table\n",
    "1. fetch the data from pdf\n",
    "2. at lesat there should be 200 pages\n",
    "3. if chunking(use the sementic chunking technique) required do chunking and then embedding\n",
    "4. store it inside the vector database(use any of them 1. mongodb 2. astradb 3. opensearch 4.milvus) ## i have not discuss then you need to explore\n",
    "5. create a index with all three index machnism(Flat, HNSW, IVF) ## i have not discuss then you need to explore\n",
    "6. create a retriever pipeline\n",
    "7. check the retriever time(which one is fastet)\n",
    "8. print the accuray score of every similarity search\n",
    "9. perform the reranking either using BM25 or MMR ## i have not discuss then you need to explore\n",
    "10. then write a prompt template\n",
    "11. generte a oputput through llm\n",
    "12. render that output over the DOCx ## i have not discuss then you need to explore\n",
    "as a additional tip: you can follow rag playlist from my youtube\n",
    "\n",
    "after completing it keep it on your github and share that link on my  mail id:\n",
    "snshrivas3365@gmail.com\n",
    "\n",
    "and share the assignment in your community chat as well by tagging krish and sunny\n",
    "\n",
    "deadline is: till firday 9PM\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dcec33",
   "metadata": {},
   "source": [
    "\n",
    "##  Contact\n",
    "\n",
    "For questions or suggestions, please open an issue or contact the development team.\n",
    "\n",
    "##  About the Author\n",
    "\n",
    "<div align=\"center\" style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); padding: 30px; margin: 20px 0; border-radius: 15px; color: white;\">\n",
    "  <img src=\"https://img.shields.io/badge/AI%20Engineer-Muhammad%20Atif%20Latif-blue?style=for-the-badge&logo=artificial-intelligence\" alt=\"AI Engineer Badge\" style=\"margin-bottom: 15px;\">\n",
    "  \n",
    "  <h2 style=\"margin: 15px 0 10px 0; font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif; font-weight: 600;\">Muhammad Atif Latif</h2>\n",
    "  \n",
    "  <p style=\"font-size: 18px; margin: 10px 0; font-weight: 500; color: #f8f9fa;\">\n",
    "     Data Scientist & Machine Learning Engineer\n",
    "  </p>\n",
    "  \n",
    "  <p style=\"font-size: 16px; line-height: 1.6; margin: 20px auto; max-width: 600px; color: #e9ecef;\">\n",
    "    Passionate about transforming data into actionable insights and building intelligent systems that solve real-world challenges. \n",
    "    Specialized in end-to-end ML pipeline development, from data preprocessing to production deployment.\n",
    "  </p>\n",
    "  \n",
    "  <div style=\"margin-top: 20px;\">\n",
    "    <span style=\"background: rgba(255,255,255,0.2); padding: 8px 16px; border-radius: 25px; margin: 5px; display: inline-block; font-size: 14px;\"> Machine Learning</span>\n",
    "    <span style=\"background: rgba(255,255,255,0.2); padding: 8px 16px; border-radius: 25px; margin: 5px; display: inline-block; font-size: 14px;\"> Deep Learning</span>\n",
    "    <span style=\"background: rgba(255,255,255,0.2); padding: 8px 16px; border-radius: 25px; margin: 5px; display: inline-block; font-size: 14px;\"> Data Analytics</span>\n",
    "    <span style=\"background: rgba(255,255,255,0.2); padding: 8px 16px; border-radius: 25px; margin: 5px; display: inline-block; font-size: 14px;\"> MLOps</span>\n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "##  Connect & Collaborate\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "### Let's Build Something Amazing Together!\n",
    "\n",
    "[![GitHub](https://img.shields.io/badge/GitHub-Follow%20Me-181717?style=for-the-badge&logo=github&logoColor=white)](https://github.com/m-Atif-Latif)\n",
    "[![LinkedIn](https://img.shields.io/badge/LinkedIn-Connect-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white)](https://www.linkedin.com/in/muhammad-atif-latif-13a171318)\n",
    "[![Kaggle](https://img.shields.io/badge/Kaggle-Compete-20BEFF?style=for-the-badge&logo=kaggle&logoColor=white)](https://www.kaggle.com/matiflatif)\n",
    "[![X](https://img.shields.io/badge/X-Follow-000000?style=for-the-badge&logo=x&logoColor=white)](https://x.com/mianatif5867)\n",
    "[![Instagram](https://img.shields.io/badge/Instagram-Follow-E4405F?style=for-the-badge&logo=instagram&logoColor=white)](https://www.instagram.com/its_atif_ai/)\n",
    "[![Email](https://img.shields.io/badge/Email-Let's%20Talk-EA4335?style=for-the-badge&logo=gmail&logoColor=white)](mailto:muhammadatiflatif67@gmail.com)\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\" style=\"margin: 40px 0;\">\n",
    "  <h3 style=\"color: #2c3e50; margin-bottom: 15px;\"> My Mission</h3>\n",
    "  <p style=\"font-size: 16px; color: #34495e; max-width: 700px; margin: 0 auto; line-height: 1.8;\">\n",
    "    <em>\"Bridging the gap between cutting-edge research and practical applications. \n",
    "    Every line of code is a step towards a more intelligent and automated future.\"</em>\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "<div align=\"center\" style=\"background-color: #f8f9fa; padding: 25px; border-radius: 10px; margin: 30px 0; border: 2px solid #e9ecef;\">\n",
    "  <h4 style=\"color: #495057; margin-bottom: 15px;\"> Open for Collaboration</h4>\n",
    "  <p style=\"color: #6c757d; font-size: 15px; margin: 10px 0;\">\n",
    "    <strong>Research Projects</strong>  <strong>Industry Applications</strong>  <strong>Open Source Contributions</strong>  <strong>Knowledge Sharing</strong>\n",
    "  </p>\n",
    "  <p style=\"color: #6c757d; font-size: 14px; margin-top: 15px;\">\n",
    "    Feel free to reach out if you have interesting projects, ideas, or just want to discuss the latest in AI/ML!\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\" style=\"padding: 20px 0;\">\n",
    "  <p style=\"color: #7f8c8d; font-size: 14px; margin: 10px 0;\">\n",
    "     <strong>If you found this project helpful, please consider giving it a star!</strong> \n",
    "  </p>\n",
    "  <p style=\"color: #95a5a6; font-size: 12px; margin-top: 15px;\">\n",
    "    Thank you for exploring this project. Your feedback and contributions are always welcome!\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div align=\"center\">\n",
    "  <img src=\"https://img.shields.io/badge/Made%20with-%20and%20Python-red?style=for-the-badge\" alt=\"Made with Love\">\n",
    "  <img src=\"https://img.shields.io/badge/AI%20Powered-Machine%20Learning-brightgreen?style=for-the-badge\" alt=\"AI Powered\">\n",
    "  <img src=\"https://img.shields.io/badge/Status-Production%20Ready-success?style=for-the-badge\" alt=\"Production Ready\">\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
