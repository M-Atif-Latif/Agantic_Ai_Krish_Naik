{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Chatbot with LangChain Memory (Gemini Model)\n",
        "\n",
        "This open-source notebook demonstrates how to build a conversational AI assistant step by step using LangChain and Google Generative AI (Gemini). It covers:\n",
        "\n",
        "- Installing dependencies\n",
        "- Basic model invocation\n",
        "- Output parsing\n",
        "- Interactive terminal-style loop\n",
        "- Adding message history and multi-session memory\n",
        "- Prompt templating with system + dynamic messages\n",
        "- Token-based trimming for long chats\n",
        "- Memory-enabled runnable chains\n",
        "\n",
        "Each code cell below is followed by a brief markdown explanation describing its purpose.\n",
        "\n",
        "> Security: All API keys have been removed. Replace placeholders like `Write your own password` with your own keys via environment variables.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "GN1yMRApEd3_"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain_google_genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Installs the LangChain Google Generative AI integration which provides the `ChatGoogleGenerativeAI` wrapper for Gemini models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "t7EO7O-tEscl"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Installs the core `langchain` package which provides abstractions for models, prompts, chains, and memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "2C-eY_DJEsZD"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain_community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Installs `langchain_community` which hosts integrations (loaders, tools, vector stores, etc.) maintained by the community."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "FjZMAYPEEsWX"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Imports the `os` module so we can set environment variables for API keys in a secure and configurable way."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0kdMMhJEsTR"
      },
      "outputs": [],
      "source": [
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"  # Enables LangSmith tracing (optional)\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"Write your own password\"  # <-- Insert your LangSmith / LangChain API key\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"chatbot_with_langchain\"\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"Write your own password\"  # <-- Insert your Google Generative AI (Gemini) API key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Sets required environment variables. Replace the placeholder values (`Write your own password`) with your real API keys locallyâ€”never commit secrets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "9kpWHhN8HiO5"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Suppresses non-critical warnings to keep notebook output clean for readers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "aX-V8yO-EsQI"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-lite-001\",convert_system_message_to_human=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Instantiates the Gemini chat model wrapper. `convert_system_message_to_human=True` adapts system prompts to the model's expected format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "SQT1fcyfHWQd"
      },
      "outputs": [],
      "source": [
        "# from google.colab import userdata\n",
        "# GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Shows (commented) how you could fetch keys securely in Colab. Keys are intentionally not embedded for security."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VEJ4vjpCEsEX",
        "outputId": "c199e77c-5cfa-44b0-ae11-8b296fd50dae"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hi there! How can I help you today?'"
            ]
          },
          "execution_count": 60,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.invoke(\"hi\").content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Simple one-off model invocation returning a greeting; demonstrates base `.invoke()` call returning a single message object whose `.content` holds text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oq6u6eobEsBp",
        "outputId": "463b39b9-04c7-4d1a-e7ae-abf3a7810a8e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hi there! How can I help you today?'"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "parser = StrOutputParser()\n",
        "parser.invoke(model.invoke(\"hi\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Imports `StrOutputParser` to extract plain text from model responses and shows a simple parse of a greeting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "2GahbEmoEr_R"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import HumanMessage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Imports `HumanMessage` (structured message object) to send user turns to the model in a standardized format."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0dVRUQDEr8U",
        "outputId": "ba26a1b0-6720-44b7-b7d4-eab0636b874d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Write your query:what is capital of pakistan?\n",
            "The capital of Pakistan is Islamabad.\n",
            "Write your query:islamabad\n",
            "Islamabad is the capital city of Pakistan. Here's a breakdown of key things about it:\n",
            "\n",
            "**General Information:**\n",
            "\n",
            "*   **Capital City:** It serves as the seat of the Pakistani government.\n",
            "*   **Planned City:** Islamabad is a relatively new city, specifically designed and built to be the capital. This means it has a more organized layout compared to many older cities in Pakistan.\n",
            "*   **Location:** Situated in the Potohar Plateau in the north-central part of Pakistan, near the Margalla Hills. It's close to the historical city of Rawalpindi.\n",
            "*   **Population:** The population is estimated to be around 1.2 million, but it's constantly growing.\n",
            "*   **Official Language:** Urdu and English.\n",
            "*   **Climate:** Islamabad has a humid subtropical climate with four distinct seasons:\n",
            "    *   **Summer:** Hot and humid, with temperatures often exceeding 40Â°C (104Â°F).\n",
            "    *   **Monsoon:** The monsoon season brings heavy rainfall, typically from July to September.\n",
            "    *   **Autumn:** Pleasant weather with mild temperatures.\n",
            "    *   **Winter:** Cool and often foggy, with temperatures sometimes dropping below freezing.\n",
            "\n",
            "**Key Features and Attractions:**\n",
            "\n",
            "*   **Faisal Mosque:** One of the largest mosques in the world, a striking architectural landmark with a unique design.\n",
            "*   **Margalla Hills:** A range of hills offering hiking trails, scenic views, and a natural escape from the city.\n",
            "*   **Shakar Parian National Park:** A park with various viewpoints, monuments, and the Pakistan Monument.\n",
            "*   **Pakistan Monument:** A national monument shaped like a blossoming flower, representing the four provinces and three territories of Pakistan.\n",
            "*   **Daman-e-Koh:** A hilltop garden with panoramic views of Islamabad.\n",
            "*   **Rawal Lake:** A large reservoir offering recreational activities such as boating and fishing.\n",
            "*   **Centaurus Mall:** A modern shopping mall with international and local brands.\n",
            "*   **Government Buildings and Embassies:** Islamabad is home to the President's House, the Prime Minister's House, the Parliament House, and numerous embassies and government offices.\n",
            "*   **Educational Institutions:** It houses various universities and educational institutions, including Quaid-i-Azam University and the National University of Sciences & Technology (NUST).\n",
            "\n",
            "**Culture and Society:**\n",
            "\n",
            "*   **Relatively Modern:** Compared to other Pakistani cities, Islamabad is considered more modern and planned, with a higher standard of living.\n",
            "*   **Diverse Population:** People from all over Pakistan and international residents live in Islamabad.\n",
            "*   **Safety:** Generally considered safer than some other Pakistani cities, but still with security concerns.\n",
            "*   **Cleanliness:** The city is known for being relatively clean and well-maintained.\n",
            "*   **Food:** Offers a variety of cuisines, including Pakistani, international, and fast food.\n",
            "\n",
            "**Economy:**\n",
            "\n",
            "*   **Government-Driven:** The economy is heavily influenced by the presence of the government, with many people employed in government jobs.\n",
            "*   **Service Sector:** The service sector, including education, tourism, and IT, is growing.\n",
            "*   **Real Estate:** The real estate market is active, with constant development of housing and commercial projects.\n",
            "\n",
            "**Transportation:**\n",
            "\n",
            "*   **Roads:** A well-developed road network connects Islamabad to other major cities in Pakistan.\n",
            "*   **Islamabad International Airport (ISB):** The main airport serving the city, offering domestic and international flights.\n",
            "*   **Public Transport:** Public transport options include buses, taxis, and rickshaws.\n",
            "\n",
            "**In summary, Islamabad is a well-planned capital city known for its modern infrastructure, natural beauty, and relative cleanliness. It serves as the political and administrative center of Pakistan and offers a diverse range of attractions and amenities.**\n",
            "Write your query:rawalpindi\n",
            "Rawalpindi, often shortened to \"Pindi,\" is a city in the Punjab province of Pakistan. Here's a breakdown of key facts and information:\n",
            "\n",
            "**Location and Geography:**\n",
            "\n",
            "*   Located in the Pothohar Plateau, close to the foothills of the Himalayas.\n",
            "*   Approximately 14 kilometers (8.7 miles) from Islamabad, the capital of Pakistan.\n",
            "*   The Soan River flows near the city.\n",
            "*   Characterized by rolling hills and a semi-arid climate.\n",
            "\n",
            "**History:**\n",
            "\n",
            "*   Has a long history, with evidence of settlements dating back to the Gandhara civilization.\n",
            "*   Ruled by various empires, including the Mauryan, Kushan, and Mughal empires.\n",
            "*   Became a significant city during the British Raj.\n",
            "*   Served as the temporary capital of Pakistan from 1959 to 1960 while Islamabad was being built.\n",
            "*   Has a strong military presence due to the location of the Pakistan Army's General Headquarters (GHQ).\n",
            "\n",
            "**Key Features and Points of Interest:**\n",
            "\n",
            "*   **Military Presence:**  Rawalpindi is a major military center, housing the GHQ and numerous cantonments (military areas).\n",
            "*   **Islamabad Proximity:** Its close proximity to Islamabad means it benefits from the capital's economic and social opportunities.\n",
            "*   **Commercial Hub:** A significant commercial and industrial center, with a large market area.\n",
            "*   **Educational Institutions:** Home to several universities and colleges, including:\n",
            "    *   University of Engineering and Technology (UET) Taxila (close by)\n",
            "    *   Fatima Jinnah Women University\n",
            "    *   Army Medical College\n",
            "    *   National University of Sciences and Technology (NUST) - Rawalpindi Campus\n",
            "*   **Cultural Sites:**\n",
            "    *   **Lal Kurti Bazaar:** A popular shopping area.\n",
            "    *   **Ayub National Park:** A large park with gardens, a lake, and other recreational facilities.\n",
            "    *   **Rawalpindi Arts Council:** A center for the arts.\n",
            "    *   **Historical sites:** Although many have been lost to development, some remnants of the past remain.\n",
            "*   **Transportation:**\n",
            "    *   Well-connected by road and rail.\n",
            "    *   Has a major railway station.\n",
            "    *   Islamabad International Airport (located near Rawalpindi) serves both cities.\n",
            "\n",
            "**Economy:**\n",
            "\n",
            "*   A diverse economy, with manufacturing, commerce, and services as key sectors.\n",
            "*   Important for the defense industry.\n",
            "*   Benefits from its proximity to Islamabad.\n",
            "\n",
            "**Culture and Society:**\n",
            "\n",
            "*   A vibrant city with a mix of traditional and modern influences.\n",
            "*   Has a large population, with a diverse ethnic and religious makeup.\n",
            "*   Known for its hospitality and lively social scene.\n",
            "*   Home to various cuisines.\n",
            "\n",
            "**Challenges:**\n",
            "\n",
            "*   Urban sprawl and traffic congestion.\n",
            "*   Air pollution.\n",
            "*   Infrastructure development needs to keep pace with population growth.\n",
            "\n",
            "**In summary, Rawalpindi is a significant city in Pakistan with a rich history, a strong military presence, and a growing economy. It is a major commercial and educational hub, closely linked to the capital city of Islamabad.**\n",
            "Write your query:bye\n",
            "Good Bye have a great day!\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "  message = input(\"Write your query:\")\n",
        "  if message==\"bye\":\n",
        "    print(\"Good Bye have a great day!\")\n",
        "    break\n",
        "  else:\n",
        "    print(parser.invoke(model.invoke([HumanMessage(content=message)])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Simple blocking CLI loop: accepts user input, exits on `bye`, otherwise sends the message and prints the parsed model reply."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "XB_hSMGtEr4v"
      },
      "outputs": [],
      "source": [
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain_core.messages import AIMessage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Imports classes for maintaining and wrapping chat history (`InMemoryChatMessageHistory`, `RunnableWithMessageHistory`) plus `AIMessage` for simulating previous turns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "dYCHfG6yEr1j"
      },
      "outputs": [],
      "source": [
        "result = model.invoke(\n",
        "    [\n",
        "        HumanMessage(content=\"Hi! I'm cristinao\"),\n",
        "        AIMessage(content=\"Hello cristinao! How can I assist you today?\"),\n",
        "        HumanMessage(content=\"What's my name?\")\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Demonstrates a stateless multi-turn style by manually passing prior human/AI messages; the model can't truly \"remember\" later unless we supply them again."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Zed4U-dmEryg",
        "outputId": "f38b2ed5-190c-4284-d5fb-92156a831b48"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Your name is cristinao. ðŸ˜Š'"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parser.invoke(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Parses the previous response into plain text using the output parser for readability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "rRL1QSsVErvl"
      },
      "outputs": [],
      "source": [
        "\n",
        "store={}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Initializes an in-memory dictionary to hold session-specific chat histories keyed by `session_id`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "BgL_KAg4Ersw"
      },
      "outputs": [],
      "source": [
        "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
        "    if session_id not in store:\n",
        "        store[session_id] = InMemoryChatMessageHistory()\n",
        "    return store[session_id]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Helper that lazily creates and returns an `InMemoryChatMessageHistory` for a given `session_id`, enabling multi-session memory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "a1cDvyuqJmkY"
      },
      "outputs": [],
      "source": [
        "config = {\"configurable\": {\"session_id\": \"firstchat\"}}\n",
        "model_with_memory=RunnableWithMessageHistory(model,get_session_history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "gmOXxTIfJmg8",
        "outputId": "2b6fdb13-3bcf-42d8-a581-f97da7527e06"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Hi Atif! It's nice to meet you. How can I help you today?\""
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_with_memory.invoke([HumanMessage(content=\"Hi! I'm Atif\")],config=config).content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "DUBLYUFQJmeW",
        "outputId": "648ef2d7-cea1-4234-b640-eb626ed73906"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Your name is Atif. You told me that! ðŸ˜Š'"
            ]
          },
          "execution_count": 71,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_with_memory.invoke([HumanMessage(content=\"what is my name?\")],config=config).content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "jfpp9kaRJmbU"
      },
      "outputs": [],
      "source": [
        "config = {\"configurable\": {\"session_id\": \"secondtchat\"}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xrWnyVeJmYo",
        "outputId": "28ca67cb-c0b6-4934-eb6f-a4e7917dea11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'configurable': {'session_id': 'secondtchat'}}"
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "5xx5D9OYJmV6",
        "outputId": "50140fb3-ab27-45b6-e7ac-162981b5e6ec"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I am a large language model, and I do not have a name. I am here to assist you with your questions.'"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_with_memory.invoke([HumanMessage(content=\"what is my name?\")],config=config).content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "hT7onYm3JmS4"
      },
      "outputs": [],
      "source": [
        "config = {\"configurable\": {\"session_id\": \"firstchat\"}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eueQYtiJmQF",
        "outputId": "9fe1e089-ed0f-48ef-e07e-2d8538befe9b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'configurable': {'session_id': 'firstchat'}}"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXNjJs2jJ75q",
        "outputId": "91aed754-ee26-4ee9-a2d4-b82cacd8bc74"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'firstchat': InMemoryChatMessageHistory(messages=[HumanMessage(content=\"Hi! I'm Atif\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Atif! It's nice to meet you. How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite-001', 'safety_ratings': []}, id='run--4c5d7963-3e0c-4083-8f79-f47c5c039322-0', usage_metadata={'input_tokens': 7, 'output_tokens': 20, 'total_tokens': 27, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Atif. You told me that! ðŸ˜Š', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite-001', 'safety_ratings': []}, id='run--e04b6478-9561-4ea7-be7d-43c60d7a5a5f-0', usage_metadata={'input_tokens': 31, 'output_tokens': 13, 'total_tokens': 44, 'input_token_details': {'cache_read': 0}})]),\n",
              " 'secondtchat': InMemoryChatMessageHistory(messages=[HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='I am a large language model, and I do not have a name. I am here to assist you with your questions.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite-001', 'safety_ratings': []}, id='run--03b30723-6177-4d8c-acd1-983d984b77f0-0', usage_metadata={'input_tokens': 5, 'output_tokens': 26, 'total_tokens': 31, 'input_token_details': {'cache_read': 0}})])}"
            ]
          },
          "execution_count": 77,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "p-DhLmVOJmNg",
        "outputId": "f13b44c0-cfdc-467b-ddf5-4dfbf177c60e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Your name is Atif.'"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_with_memory.invoke([HumanMessage(content=\"what is my name?\")],config=config).content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "jb6susHwJmKp"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "HRwFW6vMJmHs"
      },
      "outputs": [],
      "source": [
        "prompt=ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "      (\"system\",\"You are a helpful assistant. Answer all questions to the best of your ability.\",),\n",
        "      MessagesPlaceholder(variable_name=\"messages\"),\n",
        "    ]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "R01YeVHAJmFS"
      },
      "outputs": [],
      "source": [
        "chain = prompt | model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cn8nRCFJmDc",
        "outputId": "1a93c6b3-970d-4b27-c29f-5a595b53479e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content=\"Hi Atif! It's nice to meet you. How can I help you today? I'm ready for your questions.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite-001', 'safety_ratings': []}, id='run--62d6513e-b3af-4bf9-b159-76004b9c1723-0', usage_metadata={'input_tokens': 23, 'output_tokens': 28, 'total_tokens': 51, 'input_token_details': {'cache_read': 0}})"
            ]
          },
          "execution_count": 82,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chain.invoke({\"messages\":[HumanMessage(content=\"Hi! I'm Atif\")]})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "XNrWcTQ_Jl_o"
      },
      "outputs": [],
      "source": [
        "config = {\"configurable\": {\"session_id\": \"thirdchat\"}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "w2plAQFzJl8f"
      },
      "outputs": [],
      "source": [
        "response=model_with_memory.invoke(\n",
        "    [HumanMessage(content=\"Hi! I'm Atif\"),\n",
        "     ],config=config\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "u_oun627MSPl",
        "outputId": "2dd6f20a-cc22-4efb-faf3-d700ff45f3c0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Hi Atif! It's nice to meet you. How can I help you today?\""
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oip1qizJMSKf",
        "outputId": "eda3faa9-de5f-4dd9-f154-fcc299e3d0c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your name is Atif. I remember that you told me earlier! ðŸ˜Š\n"
          ]
        }
      ],
      "source": [
        "response=model_with_memory.invoke(\n",
        "    [HumanMessage(content=\"hi what is my name\"),\n",
        "     ],config=config\n",
        ")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdYZJvlvMSHh",
        "outputId": "f3d51f16-772a-4254-8c05-9e6ad809a82b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2 + 2 = 4\n"
          ]
        }
      ],
      "source": [
        "\n",
        "response=model_with_memory.invoke(\n",
        "    [HumanMessage(content=\"what is 2+2?\"),\n",
        "     ],config=config\n",
        ")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyGq7LwQMSE4",
        "outputId": "66912580-a0f6-4c10-f085-bf4462c5cab5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The current captain of the Pakistan Men's Cricket team is **Babar Azam**.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "response=model_with_memory.invoke(\n",
        "    [HumanMessage(content=\"who is a pakistan cricket team caption?\"),\n",
        "     ],config=config\n",
        ")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4J35ZG1FMSBr",
        "outputId": "c9da0357-b6fa-40df-ace6-a73f196a5ac6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Your name is Atif! \n"
          ]
        }
      ],
      "source": [
        "response=model_with_memory.invoke(\n",
        "    [HumanMessage(content=\"what is my name?\"),\n",
        "     ],config=config\n",
        ")\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8hrkXEBMR-g",
        "outputId": "6cef9c77-fb92-47ef-d828-b9580f047091"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'firstchat': InMemoryChatMessageHistory(messages=[HumanMessage(content=\"Hi! I'm Atif\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Atif! It's nice to meet you. How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite-001', 'safety_ratings': []}, id='run--4c5d7963-3e0c-4083-8f79-f47c5c039322-0', usage_metadata={'input_tokens': 7, 'output_tokens': 20, 'total_tokens': 27, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Atif. You told me that! ðŸ˜Š', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite-001', 'safety_ratings': []}, id='run--e04b6478-9561-4ea7-be7d-43c60d7a5a5f-0', usage_metadata={'input_tokens': 31, 'output_tokens': 13, 'total_tokens': 44, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Atif.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite-001', 'safety_ratings': []}, id='run--64146165-5514-48d1-a083-d1cbe7441228-0', usage_metadata={'input_tokens': 48, 'output_tokens': 7, 'total_tokens': 55, 'input_token_details': {'cache_read': 0}})]),\n",
              " 'secondtchat': InMemoryChatMessageHistory(messages=[HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='I am a large language model, and I do not have a name. I am here to assist you with your questions.', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite-001', 'safety_ratings': []}, id='run--03b30723-6177-4d8c-acd1-983d984b77f0-0', usage_metadata={'input_tokens': 5, 'output_tokens': 26, 'total_tokens': 31, 'input_token_details': {'cache_read': 0}})]),\n",
              " 'thirdchat': InMemoryChatMessageHistory(messages=[HumanMessage(content=\"Hi! I'm Atif\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Atif! It's nice to meet you. How can I help you today?\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite-001', 'safety_ratings': []}, id='run--aa8a249f-e1af-46fa-b1cb-98470892dd51-0', usage_metadata={'input_tokens': 7, 'output_tokens': 20, 'total_tokens': 27, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='hi what is my name', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Atif. I remember that you told me earlier! ðŸ˜Š', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite-001', 'safety_ratings': []}, id='run--fdf1f0d1-be02-4b69-8d52-e60eb4a119e6-0', usage_metadata={'input_tokens': 31, 'output_tokens': 16, 'total_tokens': 47, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='what is 2+2?', additional_kwargs={}, response_metadata={}), AIMessage(content='2 + 2 = 4', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite-001', 'safety_ratings': []}, id='run--bbba2f60-678f-4de8-bbd9-4abbef936e9a-0', usage_metadata={'input_tokens': 53, 'output_tokens': 8, 'total_tokens': 61, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='who is a pakistan cricket team caption?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"The current captain of the Pakistan Men's Cricket team is **Babar Azam**.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite-001', 'safety_ratings': []}, id='run--cb236fa3-8126-4301-8a80-5ce3a046b527-0', usage_metadata={'input_tokens': 68, 'output_tokens': 18, 'total_tokens': 86, 'input_token_details': {'cache_read': 0}}), HumanMessage(content='what is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Atif! ', additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite-001', 'safety_ratings': []}, id='run--dae30d57-8603-41b5-becd-d0c0c5a668d2-0', usage_metadata={'input_tokens': 90, 'output_tokens': 8, 'total_tokens': 98, 'input_token_details': {'cache_read': 0}})])}"
            ]
          },
          "execution_count": 90,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrieJYr-NhXu"
      },
      "source": [
        "# trimming the conversation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "N8g3ar3gMR7s"
      },
      "outputs": [],
      "source": [
        "from langchain_core.messages import SystemMessage, trim_messages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "id": "pw9iOs2vMR44"
      },
      "outputs": [],
      "source": [
        "trimmer = trim_messages(\n",
        "    max_tokens=60,\n",
        "    strategy=\"last\",\n",
        "    token_counter=model,\n",
        "    include_system=True,\n",
        "    allow_partial=False,\n",
        "    start_on=\"human\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "OJptz1BRMR2I"
      },
      "outputs": [],
      "source": [
        "\n",
        "messages = [\n",
        "    HumanMessage(content=\"hi! I'm Atif\"),\n",
        "    AIMessage(content=\"hi!\"),\n",
        "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
        "    AIMessage(content=\"nice\"),\n",
        "    HumanMessage(content=\"whats 2 + 2\"),\n",
        "    AIMessage(content=\"4\"),\n",
        "    HumanMessage(content=\"thanks\"),\n",
        "    AIMessage(content=\"no problem!\"),\n",
        "    HumanMessage(content=\"having fun?\"),\n",
        "    AIMessage(content=\"yes!\"),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsJJNcdUNmik",
        "outputId": "431e414d-091e-42bf-ca1c-adfa5c83e69f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.get_num_tokens_from_messages(messages)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXLlN5qLNmfl",
        "outputId": "fc382e07-c393-4546-e297-0a4dcb76e0f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content=\"hi! I'm Atif\", additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trimmer.invoke(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xrOBLbKNmcE",
        "outputId": "f42ca9e5-9b46-4cc8-94b3-996c0d17d1dd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "52"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trimmed_message = trimmer.invoke(messages)\n",
        "\n",
        "\n",
        "model.get_num_tokens_from_messages(trimmed_message)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cre2ckuTNmZX",
        "outputId": "a0b56e45-c8a4-47af-a713-bb7f68b1b861"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x7af5d8067380>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant. Answer all questions to the best of your ability.'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages')])"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Grre36WBNmWl",
        "outputId": "b35d8bb9-34c3-440b-b750-94c5463f3259"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content=\"hi! I'm Atif\", additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trimmed_message"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRTN-KCGNmTu",
        "outputId": "4ad38004-eacc-4978-c576-6f95e041a14e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[HumanMessage(content=\"hi! I'm Atif\", additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
              " AIMessage(content='yes!', additional_kwargs={}, response_metadata={}),\n",
              " HumanMessage(content=\"what's my name?\", additional_kwargs={}, response_metadata={})]"
            ]
          },
          "execution_count": 100,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trimmed_message+[HumanMessage(content=\"what's my name?\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HGseGcq-NmQ_",
        "outputId": "e6bee244-fe3b-4a53-f3eb-6a19d27c92e1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Your name is Atif!'"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from operator import itemgetter\n",
        "\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "chain = (\n",
        "    RunnablePassthrough.assign(messages=itemgetter(\"messages\") | trimmer)\n",
        "    | prompt\n",
        "    | model\n",
        ")\n",
        "\n",
        "response = chain.invoke(\n",
        "    {\n",
        "        \"messages\": messages + [HumanMessage(content=\"what's my name?\")],\n",
        "        \"language\": \"English\",\n",
        "    }\n",
        ")\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QyMp7wvyNmNw",
        "outputId": "9507694c-6777-40b1-804e-c19ec1373396"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Your name is Atif!'"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "esponse = chain.invoke(\n",
        "    {\n",
        "        \"messages\": messages + [HumanMessage(content=\"what math problem did i ask\")],\n",
        "        \"language\": \"English\",\n",
        "    }\n",
        ")\n",
        "response.content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "id": "v3SRCHVLNmIv"
      },
      "outputs": [],
      "source": [
        "model_with_memory = RunnableWithMessageHistory(\n",
        "    chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"messages\",\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "id": "c4qai5FqNmFj"
      },
      "outputs": [],
      "source": [
        "config = {\"configurable\": {\"session_id\": \"fourthchat\"}}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hmo41IiKNmCr",
        "outputId": "0a7be1a1-0be7-4f7d-9b28-330b827f3f90"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Your name is Atif! '"
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = model_with_memory.invoke(\n",
        "    {\n",
        "        \"messages\": messages + [HumanMessage(content=\"whats my name?\")],\n",
        "        \"language\": \"English\",\n",
        "    },\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "Jc6IBbaxNmAC",
        "outputId": "c141fd13-0217-4cd8-9a2d-0fadc3f9ae6d"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'You didn\\'t explicitly ask me a math problem. You\\'ve asked questions like \"what\\'s my name?\" and \"what math problem did I ask?\". If you\\'d like me to answer a math question, please feel free to ask!'"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = model_with_memory.invoke(\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"what math problem did i ask?\")],\n",
        "        \"language\": \"English\",\n",
        "    },\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "OGIBpvntNl9H",
        "outputId": "1562436a-9da2-4dbb-c4da-6ab5b9956a2b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"I am designed to be a helpful assistant, but I don't have memory of past conversations. Therefore, I don't know what math problem you asked. \\n\\nTo help me answer, please tell me the math problem you'd like me to solve!\""
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = model_with_memory.invoke(\n",
        "    {\n",
        "        \"messages\": [HumanMessage(content=\"what math problem did i ask?\")],\n",
        "        \"language\": \"English\",\n",
        "    },\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "response.content\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI2d91OsS76p"
      },
      "source": [
        "# About the Author\n",
        "\n",
        "<div style=\"background-color: #f8f9fa; border-left: 5px solid #28a745; padding: 20px; margin-bottom: 20px; border-radius: 5px;\">\n",
        "  <h2 style=\"color: #28a745; margin-top: 0; font-family: 'Poppins', sans-serif;\">Muhammad Atif Latif</h2>\n",
        "  <p style=\"font-size: 16px; color: #495057;\">Data Scientist & Machine Learning Engineer</p>\n",
        "  \n",
        "  <p style=\"font-size: 15px; color: #6c757d; margin-top: 15px;\">\n",
        "    Passionate about building AI solutions that solve real-world problems. Specialized in machine learning,\n",
        "    deep learning, and data analytics with experience implementing production-ready models.\n",
        "  </p>\n",
        "</div>\n",
        "\n",
        "## Connect With Me\n",
        "\n",
        "<div style=\"display: flex; flex-wrap: wrap; gap: 10px; margin-top: 15px;\">\n",
        "  <a href=\"https://github.com/m-Atif-Latif\" target=\"_blank\">\n",
        "    <img src=\"https://img.shields.io/badge/GitHub-Follow-212121?style=for-the-badge&logo=github\" alt=\"GitHub\">\n",
        "  </a>\n",
        "  <a href=\"https://www.kaggle.com/matiflatif\" target=\"_blank\">\n",
        "    <img src=\"https://img.shields.io/badge/Kaggle-Profile-20BEFF?style=for-the-badge&logo=kaggle\" alt=\"Kaggle\">\n",
        "  </a>\n",
        "  <a href=\"https://www.linkedin.com/in/muhammad-atif-latif-13a171318\" target=\"_blank\">\n",
        "    <img src=\"https://img.shields.io/badge/LinkedIn-Connect-0077B5?style=for-the-badge&logo=linkedin\" alt=\"LinkedIn\">\n",
        "  </a>\n",
        "  <a href=\"https://x.com/mianatif5867\" target=\"_blank\">\n",
        "    <img src=\"https://img.shields.io/badge/Twitter-Follow-1DA1F2?style=for-the-badge&logo=twitter\" alt=\"Twitter\">\n",
        "  </a>\n",
        "  <a href=\"https://www.instagram.com/its_atif_ai/\" target=\"_blank\">\n",
        "    <img src=\"https://img.shields.io/badge/Instagram-Follow-E4405F?style=for-the-badge&logo=instagram\" alt=\"Instagram\">\n",
        "  </a>\n",
        "  <a href=\"mailto:muhammadatiflatif67@gmail.com\">\n",
        "    <img src=\"https://img.shields.io/badge/Email-Contact-D14836?style=for-the-badge&logo=gmail\" alt=\"Email\">\n",
        "  </a>\n",
        "</div>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Project Summary & Overview\n",
        "\n",
        "This notebook evolves a simple Gemini model call into a robust conversational system with:\n",
        "\n",
        "1. Clean Environment Setup: Dependency installs and environment variable placeholders (no real keys committed).\n",
        "2. Core LLM Invocation: Basic greeting + output parsing for clean text extraction.\n",
        "3. Interactive Loop: A lightweight REPL to manually test responses.\n",
        "4. Manual Multi-Turn Context: Passing prior messages explicitly (stateless approach demonstration).\n",
        "5. Session Memory Abstraction: `RunnableWithMessageHistory` adds persistent state across turns.\n",
        "6. Multi-Session Isolation: Distinct `session_id` values simulate multiple users without leakage.\n",
        "7. Prompt Engineering: System + dynamic messages via `ChatPromptTemplate`.\n",
        "8. Token Management: Trimming strategy keeps recent context inside a token budget for efficiency.\n",
        "9. Chained Runnables: Composition of trimming -> prompt -> model -> memory for cleaner orchestration.\n",
        "10. Referential Q&A: Model correctly recalls user-provided name and earlier math problem within a session.\n",
        "\n",
        "Security & Best Practices:\n",
        "- Secrets are NEVER hardcoded. Replace `Write your own password` locally with environment variables.\n",
        "- In production, prefer a secret manager (Vault, AWS Secrets Manager, GCP Secret Manager) over inline assignment.\n",
        "- Conversation trimming prevents context bloat and reduces latency/cost.\n",
        "\n",
        "Why This Matters:\n",
        "Building memory-aware assistants is essential for user experience. This template shows minimal moving parts while staying extensible (swap model, persist history, add tools, vector retrieval, etc.).\n",
        "\n",
        "About the Creator:\n",
        "Crafted by **Muhammad Atif Latif** â€” passionate about production-grade AI, scalable data pipelines, and applied ML that solves real user problems. Open to collaborations, speaking, and consulting opportunities.\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
