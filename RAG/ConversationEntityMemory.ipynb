{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b1-9R6YSPj9p"
      },
      "source": [
        "#### ConversationEntityMemory is a memory class provided by LangChain, designed to track and store information about entities that arise in a conversation. It allows the AI to \"remember\" key facts about people, places, or concepts mentioned during a conversation, so it can refer back to them later on, improving the conversational experience.\n",
        "\n",
        "## Key Features:\n",
        "**Entity Tracking:** It identifies entities (e.g., names, places, concepts) and stores relevant information about them. For instance, if you mention \"Tanmay\" in one part of a conversation, it can remember details about \"Tanmay\" for later reference.\n",
        "\n",
        "**Context-Aware:** It helps the AI maintain context by remembering details about the entities mentioned during the chat, ensuring more natural, fluid conversations over time.\n",
        "\n",
        "**Customization:** You can customize what to store and how to retrieve it during future interactions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conversation Entity Memory Demonstration\n",
        "\n",
        "This notebook shows how to capture and recall entity-centric facts (people, places, concepts) across a conversation using LangChain's `ConversationEntityMemory`. It:\n",
        "\n",
        "- Installs required dependencies\n",
        "- Initializes a Gemini chat model (placeholder API key usage)\n",
        "- Loads incremental inputs to extract entities & build summaries\n",
        "- Uses `save_context` / `load_memory_variables` for evolving memory\n",
        "- Builds a `ConversationChain` with an entity-aware prompt template\n",
        "- Introspects the internal `entity_store`\n",
        "- Demonstrates follow-up queries referencing previously mentioned entities\n",
        "\n",
        "Each code cell is followed by an explanation block. All secrets are removed; replace any placeholders with your own secure credentials (e.g., environment variables, Colab secrets, or `.env`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLNHyBbaPP5V",
        "outputId": "7e2fb32b-00f4-4070-cefd-035afa320129"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.14)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Installs the core `langchain` framework providing memory abstractions, chains, and model interfaces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "csSOs0DPPSRZ",
        "outputId": "393be6c0-c0fd-4919-9543-8a586166f2a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.74)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.27)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: langsmith>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.14)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.9)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -U langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Upgrades `langchain-community` package containing integrations (loaders, tools, stores) separated from core LangChain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a1luXaapPSN4",
        "outputId": "7941aec4-c3f4-4ce4-fbb4-2b0a0356aac1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_google_genai in /usr/local/lib/python3.11/dist-packages (2.1.9)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage<0.7.0,>=0.6.18 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (0.6.18)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.68 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (0.3.74)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_google_genai) (2.11.7)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.29.5)\n",
            "Requirement already satisfied: langsmith>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (0.4.14)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (25.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain_google_genai) (0.4.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (3.11.2)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain_google_genai) (2.5.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<0.4.0,>=0.3.68->langchain_google_genai) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_google_genai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Installs the Google Generative AI integration used to access Gemini chat models through LangChain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "zCGEZOqQPSC5"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Imports the `ChatGoogleGenerativeAI` wrapper which standardizes Gemini chat responses for LangChain chains and memory modules."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "EyKFWTsjPSKP"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Suppresses non-critical warnings for a cleaner educational output view."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U7QzYfoLPSG2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY') or \"Write your own password\"  # Provide your Gemini API key securely\n",
        "os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Securely retrieves Gemini API key via Colab secrets with a placeholder fallback for open-source distribution. Replace placeholder with a real key locally; never commit secrets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "B_Znjn8IPR_W"
      },
      "outputs": [],
      "source": [
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-lite-001\",convert_system_message_to_human=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Explanation:** Instantiates the Gemini chat model; `convert_system_message_to_human=True` adapts system role prompts for this provider."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebeie55BPR4J",
        "outputId": "c040674f-2bf8-4cfd-c87d-741f91ef428c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hi there! How can I help you today?\n"
          ]
        }
      ],
      "source": [
        "print(model.invoke(\"hi\").content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "g07I_Tt2PR1K"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationEntityMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iW6_gNzMPRzM",
        "outputId": "87e9213b-13b1-468a-9247-332fe0841f7a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1182818481.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationEntityMemory(llm=model)\n",
            "/usr/local/lib/python3.11/dist-packages/pydantic/main.py:253: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  validated_self = self.__pydantic_validator__.validate_python(data, self_instance=self)\n"
          ]
        }
      ],
      "source": [
        "memory = ConversationEntityMemory(llm=model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBdlyo2FPRxd",
        "outputId": "e2eb9be4-fc2c-46d9-cae4-c490b701b969"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': '', 'entities': {}}"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_input= {\"input\": \"i am very hungry.\"}\n",
        "memory.load_memory_variables(_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LS4uv3EiPRuj",
        "outputId": "ae9bf073-a325-40ba-f2b5-0c8e72f3d36a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': '', 'entities': {'Atif': ''}}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_input= {\"input\": \"Atif is working working on a hackathon project\"}\n",
        "memory.load_memory_variables(_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f224zzikPRq8",
        "outputId": "8c34b64d-4541-44ed-d801-5e5d91ee43b9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': '', 'entities': {'Asim': '', 'Paris': ''}}"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_input= {\"input\": \"My name is asim, and I'm planning a trip to Paris.\"}\n",
        "memory.load_memory_variables(_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8W-nPajPRnQ",
        "outputId": "72f912d7-0080-4a1d-f611-3f900d393094"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': '', 'entities': {'atif': ''}}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "_input= {\"input\": \"atif is a great person who values gratitude.\"}\n",
        "memory.load_memory_variables(_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "AICFeXzwPRjI"
      },
      "outputs": [],
      "source": [
        "memory.save_context(\n",
        "    {\"Human\": \"Atif is working on a hackathon project\"},\n",
        "    {\"AI\": \"That's awesome! What's the hackathon project about?\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eMBOXEiUVNGv",
        "outputId": "65243ec9-bc11-4026-db38-74a057403b32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': \"Human: Atif is working on a hackathon project\\nAI: That's awesome! What's the hackathon project about?\",\n",
              " 'entities': {'Atif': ''}}"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory.load_memory_variables({\"input\": \"who is atif?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "QHyDP5_bVNCg"
      },
      "outputs": [],
      "source": [
        "memory.save_context(\n",
        "    {\"Human\": \"It's a machine learning project focused on healthcare.\"},\n",
        "     {\"AI\": \"Sounds exciting! Are they building a prediction model or something else?\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "F7WTmg30VM-9"
      },
      "outputs": [],
      "source": [
        "memory.save_context(\n",
        "    {\"Human\": \"Yes, they are building prediction model.\"},\n",
        "    {\"AI\": \"Wishing Sunny and Mayank all the best for their project!\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hqc9jje-VM7i",
        "outputId": "a0fb88ec-9c73-48da-a7f6-c5d29580e3bc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'history': \"Human: Atif is working on a hackathon project\\nAI: That's awesome! What's the hackathon project about?\\nHuman: It's a machine learning project focused on healthcare.\\nAI: Sounds exciting! Are they building a prediction model or something else?\\nHuman: Yes, they are building prediction model.\\nAI: Wishing Sunny and Mayank all the best for their project!\",\n",
              " 'entities': {'Atif': 'Atif is building a prediction model.'}}"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "memory.load_memory_variables({\"input\": \"who is atif?\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrVGQ-JVVM1S",
        "outputId": "d7149956-44cd-49cd-bf81-fc4dbc49ef17"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are an AI assistant helping a human keep track of facts about relevant people, places, and concepts in their life. Update the summary of the provided entity in the \"Entity\" section based on the last line of your conversation with the human. If you are writing the summary for the first time, return a single sentence.\n",
            "The update should only include facts that are relayed in the last line of conversation about the provided entity, and should only contain facts about the provided entity.\n",
            "\n",
            "If there is no new information about the provided entity or the information is not worth noting (not an important or relevant fact to remember long-term), return the existing summary unchanged.\n",
            "\n",
            "Full conversation history (for context):\n",
            "{history}\n",
            "\n",
            "Entity to summarize:\n",
            "{entity}\n",
            "\n",
            "Existing summary of {entity}:\n",
            "{summary}\n",
            "\n",
            "Last line of conversation:\n",
            "Human: {input}\n",
            "Updated summary:\n"
          ]
        }
      ],
      "source": [
        "print('You are an AI assistant helping a human keep track of facts about relevant people, places, and concepts in their life. Update the summary of the provided entity in the \"Entity\" section based on the last line of your conversation with the human. If you are writing the summary for the first time, return a single sentence.\\nThe update should only include facts that are relayed in the last line of conversation about the provided entity, and should only contain facts about the provided entity.\\n\\nIf there is no new information about the provided entity or the information is not worth noting (not an important or relevant fact to remember long-term), return the existing summary unchanged.\\n\\nFull conversation history (for context):\\n{history}\\n\\nEntity to summarize:\\n{entity}\\n\\nExisting summary of {entity}:\\n{summary}\\n\\nLast line of conversation:\\nHuman: {input}\\nUpdated summary:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s4GuKhtVMvB",
        "outputId": "3d82e912-45ed-430b-ba92-e6243a5a1802"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are an AI assistant reading the transcript of a conversation between an AI and a human. Extract all of the proper nouns from the last line of conversation. As a guideline, a proper noun is generally capitalized. You should definitely extract all names and places.\n",
            "\n",
            "The conversation history is provided just in case of a coreference (e.g. \"What do you know about him\" where \"him\" is defined in a previous line) -- ignore items mentioned there that are not in the last line.\n",
            "\n",
            "Return the output as a single comma-separated list, or NONE if there is nothing of note to return (e.g. the user is just issuing a greeting or having a simple conversation).\n",
            "\n",
            "EXAMPLE\n",
            "Conversation history:\n",
            "Person #1: how's it going today?\n",
            "AI: \"It's going great! How about you?\"\n",
            "Person #1: good! busy working on Langchain. lots to do.\n",
            "AI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\n",
            "Last line:\n",
            "Person #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff.\n",
            "Output: Langchain\n",
            "END OF EXAMPLE\n",
            "\n",
            "EXAMPLE\n",
            "Conversation history:\n",
            "Person #1: how's it going today?\n",
            "AI: \"It's going great! How about you?\"\n",
            "Person #1: good! busy working on Langchain. lots to do.\n",
            "AI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\n",
            "Last line:\n",
            "Person #1: i'm trying to improve Langchain's interfaces, the UX, its integrations with various products the user might want ... a lot of stuff. I'm working with Person #2.\n",
            "Output: Langchain, Person #2\n",
            "END OF EXAMPLE\n",
            "\n",
            "Conversation history (for reference only):\n",
            "{history}\n",
            "Last line of conversation (for extraction):\n",
            "Human: {input}\n",
            "\n",
            "Output:\n"
          ]
        }
      ],
      "source": [
        "print('You are an AI assistant reading the transcript of a conversation between an AI and a human. Extract all of the proper nouns from the last line of conversation. As a guideline, a proper noun is generally capitalized. You should definitely extract all names and places.\\n\\nThe conversation history is provided just in case of a coreference (e.g. \"What do you know about him\" where \"him\" is defined in a previous line) -- ignore items mentioned there that are not in the last line.\\n\\nReturn the output as a single comma-separated list, or NONE if there is nothing of note to return (e.g. the user is just issuing a greeting or having a simple conversation).\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how\\'s it going today?\\nAI: \"It\\'s going great! How about you?\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\\nLast line:\\nPerson #1: i\\'m trying to improve Langchain\\'s interfaces, the UX, its integrations with various products the user might want ... a lot of stuff.\\nOutput: Langchain\\nEND OF EXAMPLE\\n\\nEXAMPLE\\nConversation history:\\nPerson #1: how\\'s it going today?\\nAI: \"It\\'s going great! How about you?\"\\nPerson #1: good! busy working on Langchain. lots to do.\\nAI: \"That sounds like a lot of work! What kind of things are you doing to make Langchain better?\"\\nLast line:\\nPerson #1: i\\'m trying to improve Langchain\\'s interfaces, the UX, its integrations with various products the user might want ... a lot of stuff. I\\'m working with Person #2.\\nOutput: Langchain, Person #2\\nEND OF EXAMPLE\\n\\nConversation history (for reference only):\\n{history}\\nLast line of conversation (for extraction):\\nHuman: {input}\\n\\nOutput:')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "YAIzFrj0VMqc"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import ConversationChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "7-Ejzr3UVMmC"
      },
      "outputs": [],
      "source": [
        "from langchain.memory import ConversationEntityMemory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "X8AxoX9DVMiA"
      },
      "outputs": [],
      "source": [
        "from langchain.memory.prompt import ENTITY_MEMORY_CONVERSATION_TEMPLATE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "pCHYpBgVVMdj"
      },
      "outputs": [],
      "source": [
        "from pydantic import BaseModel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "SFmZH8YdWr6P"
      },
      "outputs": [],
      "source": [
        "from typing import List, Dict, Any"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLkYESP2WrFa",
        "outputId": "b9c949de-3c66-403e-9e11-ce43c3f94bdc"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2685706177.py:1: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
            "  conversation = ConversationChain(\n"
          ]
        }
      ],
      "source": [
        "conversation = ConversationChain(\n",
        "    llm=model,\n",
        "    verbose=True,\n",
        "    prompt=ENTITY_MEMORY_CONVERSATION_TEMPLATE,\n",
        "    memory=ConversationEntityMemory(llm=model)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        },
        "id": "nZaf4phFWrA-",
        "outputId": "c5cb5fdd-be95-49ec-c2d6-43c47a39f9c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Deven': '', 'Sam': ''}\n",
            "\n",
            "Current conversation:\n",
            "\n",
            "Last line:\n",
            "Human: Deven & Sam are working on a hackathon project\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Okay, that's great! I'm ready to hear more about their hackathon project. What are they working on? What's the project about? I'm interested to know!\""
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"Deven & Sam are working on a hackathon project\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yy9OL9qRWq8c",
        "outputId": "9b5ba627-4c99-4887-c843-4e83070f13a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Deven': 'Deven is working on a hackathon project.',\n",
              " 'Sam': 'Sam is working on a hackathon project.'}"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.memory.entity_store.store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "PCndNVeRWq0c",
        "outputId": "80086ea9-4276-430e-bee4-12677e1e119a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Langchain': ''}\n",
            "\n",
            "Current conversation:\n",
            "Human: Deven & Sam are working on a hackathon project\n",
            "AI: Okay, that's great! I'm ready to hear more about their hackathon project. What are they working on? What's the project about? I'm interested to know!\n",
            "Last line:\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"That's an interesting challenge! Adding more complex memory structures to Langchain could significantly improve its capabilities. I'm curious to know what kind of memory structures they're exploring. Are they looking at different types of memory, like episodic or semantic memory? Or are they focusing on improving the existing memory components? I'm also wondering what specific problems they are trying to solve by enhancing Langchain's memory.\""
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"They are trying to add more complex memory structures to Langchain\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 558
        },
        "id": "K3CNy_6HWqr1",
        "outputId": "23443ae7-eb49-48b3-bd97-584e0c2d6406"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{}\n",
            "\n",
            "Current conversation:\n",
            "Human: Deven & Sam are working on a hackathon project\n",
            "AI: Okay, that's great! I'm ready to hear more about their hackathon project. What are they working on? What's the project about? I'm interested to know!\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "AI: That's an interesting challenge! Adding more complex memory structures to Langchain could significantly improve its capabilities. I'm curious to know what kind of memory structures they're exploring. Are they looking at different types of memory, like episodic or semantic memory? Or are they focusing on improving the existing memory components? I'm also wondering what specific problems they are trying to solve by enhancing Langchain's memory.\n",
            "Last line:\n",
            "Human: They are adding in a key-value store for entities mentioned so far in the conversation.\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'That sounds like a very practical and useful addition! A key-value store for entities would allow Langchain to better track and utilize information about the entities discussed in the conversation. This could be used for a variety of things, such as:\\n\\n*   **Entity resolution:** Identifying and linking mentions of the same entity across different parts of the conversation.\\n*   **Fact retrieval:** Quickly accessing information about specific entities.\\n*   **Contextual understanding:** Remembering and using information about entities to understand the nuances of the conversation.\\n\\nWhat key-value store are they using? How are they planning to populate and update the store?'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"They are adding in a key-value store for entities mentioned so far in the conversation.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "apoOeUoQWqpd",
        "outputId": "30844a68-90b3-4c81-8bfd-b9498aeb07ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Deven': 'Deven is working on a hackathon project.', 'Sam': 'Sam is working on a hackathon project.'}\n",
            "\n",
            "Current conversation:\n",
            "Human: Deven & Sam are working on a hackathon project\n",
            "AI: Okay, that's great! I'm ready to hear more about their hackathon project. What are they working on? What's the project about? I'm interested to know!\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "AI: That's an interesting challenge! Adding more complex memory structures to Langchain could significantly improve its capabilities. I'm curious to know what kind of memory structures they're exploring. Are they looking at different types of memory, like episodic or semantic memory? Or are they focusing on improving the existing memory components? I'm also wondering what specific problems they are trying to solve by enhancing Langchain's memory.\n",
            "Human: They are adding in a key-value store for entities mentioned so far in the conversation.\n",
            "AI: That sounds like a very practical and useful addition! A key-value store for entities would allow Langchain to better track and utilize information about the entities discussed in the conversation. This could be used for a variety of things, such as:\n",
            "\n",
            "*   **Entity resolution:** Identifying and linking mentions of the same entity across different parts of the conversation.\n",
            "*   **Fact retrieval:** Quickly accessing information about specific entities.\n",
            "*   **Contextual understanding:** Remembering and using information about entities to understand the nuances of the conversation.\n",
            "\n",
            "What key-value store are they using? How are they planning to populate and update the store?\n",
            "Last line:\n",
            "Human: What do you know about Deven & Sam?\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I know that both Deven and Sam are working on a hackathon project together. They are currently focused on enhancing Langchain by adding a key-value store to track entities mentioned in the conversation.'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"What do you know about Deven & Sam?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr7L9E6KWqk4",
        "outputId": "a5d04fd6-6d48-4d90-a167-8d7e78e2e9d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Deven': 'Deven is working on a hackathon project.',\n",
            " 'Langchain': 'They are trying to add more complex memory structures to it.',\n",
            " 'Sam': 'Sam is working on a hackathon project.'}\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "pprint(conversation.memory.entity_store.store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "7S0MytOqWqgi",
        "outputId": "b9ebbc33-c657-4cce-ac98-d5440b8bba31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Sam': 'Sam is working on a hackathon project.', 'Daimon': ''}\n",
            "\n",
            "Current conversation:\n",
            "Human: They are trying to add more complex memory structures to Langchain\n",
            "AI: That's an interesting challenge! Adding more complex memory structures to Langchain could significantly improve its capabilities. I'm curious to know what kind of memory structures they're exploring. Are they looking at different types of memory, like episodic or semantic memory? Or are they focusing on improving the existing memory components? I'm also wondering what specific problems they are trying to solve by enhancing Langchain's memory.\n",
            "Human: They are adding in a key-value store for entities mentioned so far in the conversation.\n",
            "AI: That sounds like a very practical and useful addition! A key-value store for entities would allow Langchain to better track and utilize information about the entities discussed in the conversation. This could be used for a variety of things, such as:\n",
            "\n",
            "*   **Entity resolution:** Identifying and linking mentions of the same entity across different parts of the conversation.\n",
            "*   **Fact retrieval:** Quickly accessing information about specific entities.\n",
            "*   **Contextual understanding:** Remembering and using information about entities to understand the nuances of the conversation.\n",
            "\n",
            "What key-value store are they using? How are they planning to populate and update the store?\n",
            "Human: What do you know about Deven & Sam?\n",
            "AI: I know that both Deven and Sam are working on a hackathon project together. They are currently focused on enhancing Langchain by adding a key-value store to track entities mentioned in the conversation.\n",
            "Last line:\n",
            "Human: Sam is the founder of a company called Daimon.\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"That's interesting! So Sam is the founder of a company called Daimon, and he's working on a hackathon project with Deven that involves improving Langchain. This suggests that the hackathon project might be related to Daimon's work or interests. It would be interesting to know more about Daimon and how Sam's work there relates to the Langchain project.\""
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"Sam is the founder of a company called Daimon.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOaKteQIWqcQ",
        "outputId": "a8386283-bbb7-4954-a4ee-e750c0d3e52a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Daimon': 'Sam is the founder of a company called Daimon.',\n",
            " 'Deven': 'Deven is working on a hackathon project.',\n",
            " 'Langchain': 'They are trying to add more complex memory structures to it.',\n",
            " 'Sam': 'Sam is the founder of a company called Daimon.'}\n"
          ]
        }
      ],
      "source": [
        "from pprint import pprint\n",
        "pprint(conversation.memory.entity_store.store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "yTvQJtK6WqX0",
        "outputId": "b3c7e612-1b6f-421e-8ecb-df6d6368282f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mYou are an assistant to a human, powered by a large language model trained by OpenAI.\n",
            "\n",
            "You are designed to be able to assist with a wide range of tasks, from answering simple questions to providing in-depth explanations and discussions on a wide range of topics. As a language model, you are able to generate human-like text based on the input you receive, allowing you to engage in natural-sounding conversations and provide responses that are coherent and relevant to the topic at hand.\n",
            "\n",
            "You are constantly learning and improving, and your capabilities are constantly evolving. You are able to process and understand large amounts of text, and can use this knowledge to provide accurate and informative responses to a wide range of questions. You have access to some personalized information provided by the human in the Context section below. Additionally, you are able to generate your own text based on the input you receive, allowing you to engage in discussions and provide explanations and descriptions on a wide range of topics.\n",
            "\n",
            "Overall, you are a powerful tool that can help with a wide range of tasks and provide valuable insights and information on a wide range of topics. Whether the human needs help with a specific question or just wants to have a conversation about a particular topic, you are here to assist.\n",
            "\n",
            "Context:\n",
            "{'Sam': 'Sam is the founder of a company called Daimon.'}\n",
            "\n",
            "Current conversation:\n",
            "Human: They are adding in a key-value store for entities mentioned so far in the conversation.\n",
            "AI: That sounds like a very practical and useful addition! A key-value store for entities would allow Langchain to better track and utilize information about the entities discussed in the conversation. This could be used for a variety of things, such as:\n",
            "\n",
            "*   **Entity resolution:** Identifying and linking mentions of the same entity across different parts of the conversation.\n",
            "*   **Fact retrieval:** Quickly accessing information about specific entities.\n",
            "*   **Contextual understanding:** Remembering and using information about entities to understand the nuances of the conversation.\n",
            "\n",
            "What key-value store are they using? How are they planning to populate and update the store?\n",
            "Human: What do you know about Deven & Sam?\n",
            "AI: I know that both Deven and Sam are working on a hackathon project together. They are currently focused on enhancing Langchain by adding a key-value store to track entities mentioned in the conversation.\n",
            "Human: Sam is the founder of a company called Daimon.\n",
            "AI: That's interesting! So Sam is the founder of a company called Daimon, and he's working on a hackathon project with Deven that involves improving Langchain. This suggests that the hackathon project might be related to Daimon's work or interests. It would be interesting to know more about Daimon and how Sam's work there relates to the Langchain project.\n",
            "Last line:\n",
            "Human: What do you know about Sam?\n",
            "You:\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I know that Sam is the founder of a company called Daimon. He is also working on a hackathon project with Deven to improve Langchain by adding a key-value store for entities mentioned in the conversation.'"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "conversation.predict(input=\"What do you know about Sam?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FW_QR-eIY9BP"
      },
      "source": [
        "# About the Author\n",
        "\n",
        "<div style=\"background-color: #f8f9fa; border-left: 5px solid #28a745; padding: 20px; margin-bottom: 20px; border-radius: 5px;\">\n",
        "  <h2 style=\"color: #28a745; margin-top: 0; font-family: 'Poppins', sans-serif;\">Muhammad Atif Latif</h2>\n",
        "  <p style=\"font-size: 16px; color: #495057;\">Data Scientist & Machine Learning Engineer</p>\n",
        "  \n",
        "  <p style=\"font-size: 15px; color: #6c757d; margin-top: 15px;\">\n",
        "    Passionate about building AI solutions that solve real-world problems. Specialized in machine learning,\n",
        "    deep learning, and data analytics with experience implementing production-ready models.\n",
        "  </p>\n",
        "</div>\n",
        "\n",
        "## Connect With Me\n",
        "\n",
        "<div style=\"display: flex; flex-wrap: wrap; gap: 10px; margin-top: 15px;\">\n",
        "  <a href=\"https://github.com/m-Atif-Latif\" target=\"_blank\">\n",
        "    <img src=\"https://img.shields.io/badge/GitHub-Follow-212121?style=for-the-badge&logo=github\" alt=\"GitHub\">\n",
        "  </a>\n",
        "  <a href=\"https://www.kaggle.com/matiflatif\" target=\"_blank\">\n",
        "    <img src=\"https://img.shields.io/badge/Kaggle-Profile-20BEFF?style=for-the-badge&logo=kaggle\" alt=\"Kaggle\">\n",
        "  </a>\n",
        "  <a href=\"https://www.linkedin.com/in/muhammad-atif-latif-13a171318\" target=\"_blank\">\n",
        "    <img src=\"https://img.shields.io/badge/LinkedIn-Connect-0077B5?style=for-the-badge&logo=linkedin\" alt=\"LinkedIn\">\n",
        "  </a>\n",
        "  <a href=\"https://x.com/mianatif5867\" target=\"_blank\">\n",
        "    <img src=\"https://img.shields.io/badge/Twitter-Follow-1DA1F2?style=for-the-badge&logo=twitter\" alt=\"Twitter\">\n",
        "  </a>\n",
        "  <a href=\"https://www.instagram.com/its_atif_ai/\" target=\"_blank\">\n",
        "    <img src=\"https://img.shields.io/badge/Instagram-Follow-E4405F?style=for-the-badge&logo=instagram\" alt=\"Instagram\">\n",
        "  </a>\n",
        "  <a href=\"mailto:muhammadatiflatif67@gmail.com\">\n",
        "    <img src=\"https://img.shields.io/badge/Email-Contact-D14836?style=for-the-badge&logo=gmail\" alt=\"Email\">\n",
        "  </a>\n",
        "</div>\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Notebook Summary\n",
        "\n",
        "In this walkthrough you:\n",
        "- Installed LangChain core + community + Gemini integration.\n",
        "- Initialized a Gemini model with secure (placeholder) key loading.\n",
        "- Created a `ConversationEntityMemory` instance to capture entities and their evolving summaries.\n",
        "- Incrementally fed inputs containing names and contextual facts (Atif, Sam, Deven) and persisted them via `save_context`.\n",
        "- Queried memory using `load_memory_variables` to retrieve relevant entity information for follow-up questions.\n",
        "- Used the built-in `ENTITY_MEMORY_CONVERSATION_TEMPLATE` within a `ConversationChain` to automatically extract and update entity summaries.\n",
        "- Inspected the underlying `entity_store` to verify stored structured knowledge.\n",
        "\n",
        "Why it matters: Entity memory enables richer, more personalized conversational agents by grounding responses in previously mentioned facts without overloading token context.\n",
        "\n",
        "Crafted and curated by **Muhammad Atif Latif**  delivering practical, production-focused AI. Star the repo and connect below to follow more LangChain, RAG, and MLOps explorations."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
